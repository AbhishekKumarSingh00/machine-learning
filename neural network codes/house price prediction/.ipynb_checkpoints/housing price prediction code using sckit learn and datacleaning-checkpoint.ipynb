{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=pd.read_csv('./Train/Train_Data.csv')\n",
    "x_test=pd.read_csv('./Test/Test_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 81 columns):\n",
      "Id               1100 non-null int64\n",
      "MSSubClass       1100 non-null int64\n",
      "MSZoning         1100 non-null object\n",
      "LotFrontage      908 non-null float64\n",
      "LotArea          1100 non-null int64\n",
      "Street           1100 non-null object\n",
      "Alley            69 non-null object\n",
      "LotShape         1100 non-null object\n",
      "LandContour      1100 non-null object\n",
      "Utilities        1100 non-null object\n",
      "LotConfig        1100 non-null object\n",
      "LandSlope        1100 non-null object\n",
      "Neighborhood     1100 non-null object\n",
      "Condition1       1100 non-null object\n",
      "Condition2       1100 non-null object\n",
      "BldgType         1100 non-null object\n",
      "HouseStyle       1100 non-null object\n",
      "OverallQual      1100 non-null int64\n",
      "OverallCond      1100 non-null int64\n",
      "YearBuilt        1100 non-null int64\n",
      "YearRemodAdd     1100 non-null int64\n",
      "RoofStyle        1100 non-null object\n",
      "RoofMatl         1100 non-null object\n",
      "Exterior1st      1100 non-null object\n",
      "Exterior2nd      1100 non-null object\n",
      "MasVnrType       1094 non-null object\n",
      "MasVnrArea       1094 non-null float64\n",
      "ExterQual        1100 non-null object\n",
      "ExterCond        1100 non-null object\n",
      "Foundation       1100 non-null object\n",
      "BsmtQual         1069 non-null object\n",
      "BsmtCond         1069 non-null object\n",
      "BsmtExposure     1068 non-null object\n",
      "BsmtFinType1     1069 non-null object\n",
      "BsmtFinSF1       1100 non-null int64\n",
      "BsmtFinType2     1068 non-null object\n",
      "BsmtFinSF2       1100 non-null int64\n",
      "BsmtUnfSF        1100 non-null int64\n",
      "TotalBsmtSF      1100 non-null int64\n",
      "Heating          1100 non-null object\n",
      "HeatingQC        1100 non-null object\n",
      "CentralAir       1100 non-null object\n",
      "Electrical       1100 non-null object\n",
      "1stFlrSF         1100 non-null int64\n",
      "2ndFlrSF         1100 non-null int64\n",
      "LowQualFinSF     1100 non-null int64\n",
      "GrLivArea        1100 non-null int64\n",
      "BsmtFullBath     1100 non-null int64\n",
      "BsmtHalfBath     1100 non-null int64\n",
      "FullBath         1100 non-null int64\n",
      "HalfBath         1100 non-null int64\n",
      "BedroomAbvGr     1100 non-null int64\n",
      "KitchenAbvGr     1100 non-null int64\n",
      "KitchenQual      1100 non-null object\n",
      "TotRmsAbvGrd     1100 non-null int64\n",
      "Functional       1100 non-null object\n",
      "Fireplaces       1100 non-null int64\n",
      "FireplaceQu      576 non-null object\n",
      "GarageType       1039 non-null object\n",
      "GarageYrBlt      1039 non-null float64\n",
      "GarageFinish     1039 non-null object\n",
      "GarageCars       1100 non-null int64\n",
      "GarageArea       1100 non-null int64\n",
      "GarageQual       1039 non-null object\n",
      "GarageCond       1039 non-null object\n",
      "PavedDrive       1100 non-null object\n",
      "WoodDeckSF       1100 non-null int64\n",
      "OpenPorchSF      1100 non-null int64\n",
      "EnclosedPorch    1100 non-null int64\n",
      "3SsnPorch        1100 non-null int64\n",
      "ScreenPorch      1100 non-null int64\n",
      "PoolArea         1100 non-null int64\n",
      "PoolQC           2 non-null object\n",
      "Fence            208 non-null object\n",
      "MiscFeature      46 non-null object\n",
      "MiscVal          1100 non-null int64\n",
      "MoSold           1100 non-null int64\n",
      "YrSold           1100 non-null int64\n",
      "SaleType         1100 non-null object\n",
      "SaleCondition    1100 non-null object\n",
      "SalePrice        1100 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 696.2+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 80 columns):\n",
      "Id               360 non-null int64\n",
      "MSSubClass       360 non-null int64\n",
      "MSZoning         360 non-null object\n",
      "LotFrontage      293 non-null float64\n",
      "LotArea          360 non-null int64\n",
      "Street           360 non-null object\n",
      "Alley            22 non-null object\n",
      "LotShape         360 non-null object\n",
      "LandContour      360 non-null object\n",
      "Utilities        360 non-null object\n",
      "LotConfig        360 non-null object\n",
      "LandSlope        360 non-null object\n",
      "Neighborhood     360 non-null object\n",
      "Condition1       360 non-null object\n",
      "Condition2       360 non-null object\n",
      "BldgType         360 non-null object\n",
      "HouseStyle       360 non-null object\n",
      "OverallQual      360 non-null int64\n",
      "OverallCond      360 non-null int64\n",
      "YearBuilt        360 non-null int64\n",
      "YearRemodAdd     360 non-null int64\n",
      "RoofStyle        360 non-null object\n",
      "RoofMatl         360 non-null object\n",
      "Exterior1st      360 non-null object\n",
      "Exterior2nd      360 non-null object\n",
      "MasVnrType       358 non-null object\n",
      "MasVnrArea       358 non-null float64\n",
      "ExterQual        360 non-null object\n",
      "ExterCond        360 non-null object\n",
      "Foundation       360 non-null object\n",
      "BsmtQual         354 non-null object\n",
      "BsmtCond         354 non-null object\n",
      "BsmtExposure     354 non-null object\n",
      "BsmtFinType1     354 non-null object\n",
      "BsmtFinSF1       360 non-null int64\n",
      "BsmtFinType2     354 non-null object\n",
      "BsmtFinSF2       360 non-null int64\n",
      "BsmtUnfSF        360 non-null int64\n",
      "TotalBsmtSF      360 non-null int64\n",
      "Heating          360 non-null object\n",
      "HeatingQC        360 non-null object\n",
      "CentralAir       360 non-null object\n",
      "Electrical       359 non-null object\n",
      "1stFlrSF         360 non-null int64\n",
      "2ndFlrSF         360 non-null int64\n",
      "LowQualFinSF     360 non-null int64\n",
      "GrLivArea        360 non-null int64\n",
      "BsmtFullBath     360 non-null int64\n",
      "BsmtHalfBath     360 non-null int64\n",
      "FullBath         360 non-null int64\n",
      "HalfBath         360 non-null int64\n",
      "BedroomAbvGr     360 non-null int64\n",
      "KitchenAbvGr     360 non-null int64\n",
      "KitchenQual      360 non-null object\n",
      "TotRmsAbvGrd     360 non-null int64\n",
      "Functional       360 non-null object\n",
      "Fireplaces       360 non-null int64\n",
      "FireplaceQu      194 non-null object\n",
      "GarageType       340 non-null object\n",
      "GarageYrBlt      340 non-null float64\n",
      "GarageFinish     340 non-null object\n",
      "GarageCars       360 non-null int64\n",
      "GarageArea       360 non-null int64\n",
      "GarageQual       340 non-null object\n",
      "GarageCond       340 non-null object\n",
      "PavedDrive       360 non-null object\n",
      "WoodDeckSF       360 non-null int64\n",
      "OpenPorchSF      360 non-null int64\n",
      "EnclosedPorch    360 non-null int64\n",
      "3SsnPorch        360 non-null int64\n",
      "ScreenPorch      360 non-null int64\n",
      "PoolArea         360 non-null int64\n",
      "PoolQC           5 non-null object\n",
      "Fence            73 non-null object\n",
      "MiscFeature      8 non-null object\n",
      "MiscVal          360 non-null int64\n",
      "MoSold           360 non-null int64\n",
      "YrSold           360 non-null int64\n",
      "SaleType         360 non-null object\n",
      "SaleCondition    360 non-null object\n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 225.1+ KB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x_train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=['SalePrice'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 80 columns):\n",
      "Id               1100 non-null int64\n",
      "MSSubClass       1100 non-null int64\n",
      "MSZoning         1100 non-null object\n",
      "LotFrontage      908 non-null float64\n",
      "LotArea          1100 non-null int64\n",
      "Street           1100 non-null object\n",
      "Alley            69 non-null object\n",
      "LotShape         1100 non-null object\n",
      "LandContour      1100 non-null object\n",
      "Utilities        1100 non-null object\n",
      "LotConfig        1100 non-null object\n",
      "LandSlope        1100 non-null object\n",
      "Neighborhood     1100 non-null object\n",
      "Condition1       1100 non-null object\n",
      "Condition2       1100 non-null object\n",
      "BldgType         1100 non-null object\n",
      "HouseStyle       1100 non-null object\n",
      "OverallQual      1100 non-null int64\n",
      "OverallCond      1100 non-null int64\n",
      "YearBuilt        1100 non-null int64\n",
      "YearRemodAdd     1100 non-null int64\n",
      "RoofStyle        1100 non-null object\n",
      "RoofMatl         1100 non-null object\n",
      "Exterior1st      1100 non-null object\n",
      "Exterior2nd      1100 non-null object\n",
      "MasVnrType       1094 non-null object\n",
      "MasVnrArea       1094 non-null float64\n",
      "ExterQual        1100 non-null object\n",
      "ExterCond        1100 non-null object\n",
      "Foundation       1100 non-null object\n",
      "BsmtQual         1069 non-null object\n",
      "BsmtCond         1069 non-null object\n",
      "BsmtExposure     1068 non-null object\n",
      "BsmtFinType1     1069 non-null object\n",
      "BsmtFinSF1       1100 non-null int64\n",
      "BsmtFinType2     1068 non-null object\n",
      "BsmtFinSF2       1100 non-null int64\n",
      "BsmtUnfSF        1100 non-null int64\n",
      "TotalBsmtSF      1100 non-null int64\n",
      "Heating          1100 non-null object\n",
      "HeatingQC        1100 non-null object\n",
      "CentralAir       1100 non-null object\n",
      "Electrical       1100 non-null object\n",
      "1stFlrSF         1100 non-null int64\n",
      "2ndFlrSF         1100 non-null int64\n",
      "LowQualFinSF     1100 non-null int64\n",
      "GrLivArea        1100 non-null int64\n",
      "BsmtFullBath     1100 non-null int64\n",
      "BsmtHalfBath     1100 non-null int64\n",
      "FullBath         1100 non-null int64\n",
      "HalfBath         1100 non-null int64\n",
      "BedroomAbvGr     1100 non-null int64\n",
      "KitchenAbvGr     1100 non-null int64\n",
      "KitchenQual      1100 non-null object\n",
      "TotRmsAbvGrd     1100 non-null int64\n",
      "Functional       1100 non-null object\n",
      "Fireplaces       1100 non-null int64\n",
      "FireplaceQu      576 non-null object\n",
      "GarageType       1039 non-null object\n",
      "GarageYrBlt      1039 non-null float64\n",
      "GarageFinish     1039 non-null object\n",
      "GarageCars       1100 non-null int64\n",
      "GarageArea       1100 non-null int64\n",
      "GarageQual       1039 non-null object\n",
      "GarageCond       1039 non-null object\n",
      "PavedDrive       1100 non-null object\n",
      "WoodDeckSF       1100 non-null int64\n",
      "OpenPorchSF      1100 non-null int64\n",
      "EnclosedPorch    1100 non-null int64\n",
      "3SsnPorch        1100 non-null int64\n",
      "ScreenPorch      1100 non-null int64\n",
      "PoolArea         1100 non-null int64\n",
      "PoolQC           2 non-null object\n",
      "Fence            208 non-null object\n",
      "MiscFeature      46 non-null object\n",
      "MiscVal          1100 non-null int64\n",
      "MoSold           1100 non-null int64\n",
      "YrSold           1100 non-null int64\n",
      "SaleType         1100 non-null object\n",
      "SaleCondition    1100 non-null object\n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 687.6+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[x_train,x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9758</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1103</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnWw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1104</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>79.0</td>\n",
       "      <td>8910</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1105</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0    1101          30       RL         60.0     8400   Pave   NaN      Reg   \n",
       "1    1102          20       RL         61.0     9758   Pave   NaN      IR1   \n",
       "2    1103          20       RL         70.0     7000   Pave   NaN      Reg   \n",
       "3    1104          20       RL         79.0     8910   Pave   NaN      Reg   \n",
       "4    1105         160       RM         24.0     2016   Pave   NaN      Reg   \n",
       "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "355  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "356  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "357  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "358  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "359  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "    LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0           Bnk    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "1           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "2           Lvl    AllPub  ...           0        0    NaN   MnWw         NaN   \n",
       "3           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "..          ...       ...  ...         ...      ...    ...    ...         ...   \n",
       "355         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "356         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "357         Lvl    AllPub  ...           0        0    NaN  GdPrv        Shed   \n",
       "358         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "359         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "\n",
       "    MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         0      1    2009        WD         Normal  \n",
       "1         0      7    2007        WD         Normal  \n",
       "2         0      4    2007        WD         Family  \n",
       "3         0      7    2006        WD         Normal  \n",
       "4         0      4    2007        WD         Normal  \n",
       "..      ...    ...     ...       ...            ...  \n",
       "355       0      8    2007        WD         Normal  \n",
       "356       0      2    2010        WD         Normal  \n",
       "357    2500      5    2010        WD         Normal  \n",
       "358       0      4    2010        WD         Normal  \n",
       "359       0      6    2008        WD         Normal  \n",
       "\n",
       "[360 rows x 80 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>1096</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9317</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1096</td>\n",
       "      <td>1097</td>\n",
       "      <td>70</td>\n",
       "      <td>RM</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6882</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>1098</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3696</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1098</td>\n",
       "      <td>1099</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1099</td>\n",
       "      <td>1100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11880</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1095  1096          20       RL         78.0     9317   Pave   NaN      IR1   \n",
       "1096  1097          70       RM         60.0     6882   Pave   NaN      Reg   \n",
       "1097  1098         120       RL          NaN     3696   Pave   NaN      Reg   \n",
       "1098  1099          50       RM         50.0     6000   Pave   NaN      Reg   \n",
       "1099  1100          20       RL         82.0    11880   Pave   NaN      IR1   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0            Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1            Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "3            Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "4            Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "...          ...       ...  ...         ...      ...    ...   ...         ...   \n",
       "1095         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1096         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1097         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1098         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "1099         Lvl    AllPub  ...           0        0    NaN   NaN         NaN   \n",
       "\n",
       "     MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0          0      2    2008        WD         Normal  \n",
       "1          0      5    2007        WD         Normal  \n",
       "2          0      9    2008        WD         Normal  \n",
       "3          0      2    2006        WD        Abnorml  \n",
       "4          0     12    2008        WD         Normal  \n",
       "...      ...    ...     ...       ...            ...  \n",
       "1095       0      3    2007        WD         Normal  \n",
       "1096       0      3    2007        WD         Normal  \n",
       "1097       0     10    2007        WD         Normal  \n",
       "1098       0      7    2009        WD         Normal  \n",
       "1099       0      4    2009       COD        Abnorml  \n",
       "\n",
       "[1100 rows x 80 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 0 to 359\n",
      "Data columns (total 80 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>496</td>\n",
       "      <td>30</td>\n",
       "      <td>C (all)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7879</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>497</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12692</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>498</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>499</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7800</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7535</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnWw</td>\n",
       "      <td>Shed</td>\n",
       "      <td>480</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0      1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1      2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2      3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3      4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4      5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "..   ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "495  496          30  C (all)         60.0     7879   Pave   NaN      Reg   \n",
       "496  497          20       RL          NaN    12692   Pave   NaN      IR1   \n",
       "497  498          50       RL         60.0     9120   Pave  Pave      Reg   \n",
       "498  499          20       RL         65.0     7800   Pave   NaN      Reg   \n",
       "499  500          20       RL         70.0     7535   Pave   NaN      IR1   \n",
       "\n",
       "    LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "1           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "2           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "3           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4           Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "..          ...       ...  ...         ...      ...    ...    ...         ...   \n",
       "495         Lvl    AllPub  ...           0        0    NaN   GdWo         NaN   \n",
       "496         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "497         Lvl    AllPub  ...           0        0    NaN  GdPrv         NaN   \n",
       "498         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "499         Lvl    AllPub  ...           0        0    NaN   MnWw        Shed   \n",
       "\n",
       "    MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         0      2    2008        WD         Normal  \n",
       "1         0      5    2007        WD         Normal  \n",
       "2         0      9    2008        WD         Normal  \n",
       "3         0      2    2006        WD        Abnorml  \n",
       "4         0     12    2008        WD         Normal  \n",
       "..      ...    ...     ...       ...            ...  \n",
       "495       0     11    2009        WD        Abnorml  \n",
       "496       0      5    2007        WD         Normal  \n",
       "497       0      6    2008        WD         Normal  \n",
       "498       0      6    2009        WD         Normal  \n",
       "499     480      6    2007        WD         Normal  \n",
       "\n",
       "[500 rows x 80 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 80)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452\n"
     ]
    }
   ],
   "source": [
    "xyz=dataset.count()\n",
    "print(xyz[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=dataset.count()\n",
    "N=dataset.shape[0]\n",
    "missing_obj_col=[]\n",
    "for i in range(dataset.shape[1]):\n",
    "    if col[i]!=N:\n",
    "        missing_obj_col.append(dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'Alley',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Electrical',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_obj_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0\n"
     ]
    }
   ],
   "source": [
    "mean=float(round(np.mean(dataset['LotFrontage'])))\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['LotFrontage'].fillna(value=mean,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset['LotFrontage'].shape)\n",
    "missing_obj_col.remove('LotFrontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None       864\n",
      "BrkFace    445\n",
      "Stone      128\n",
      "BrkCmn      15\n",
      "Name: MasVnrType, dtype: int64\n",
      "1452\n"
     ]
    }
   ],
   "source": [
    "print(dataset['MasVnrType'].value_counts())\n",
    "print(dataset['MasVnrType'].count())\n",
    "missing_obj_col.remove('MasVnrType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['MasVnrType'].fillna(value='None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['MasVnrType'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0      861\n",
      "72.0       8\n",
      "180.0      8\n",
      "108.0      8\n",
      "120.0      7\n",
      "        ... \n",
      "651.0      1\n",
      "337.0      1\n",
      "415.0      1\n",
      "293.0      1\n",
      "621.0      1\n",
      "Name: MasVnrArea, Length: 327, dtype: int64\n",
      "1452\n"
     ]
    }
   ],
   "source": [
    "print(dataset['MasVnrArea'].value_counts())\n",
    "print(dataset['MasVnrArea'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "dataset['MasVnrArea'].fillna(value=0.0,inplace=True)\n",
    "print(dataset['MasVnrArea'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_obj_col.remove('MasVnrArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBrkr    1334\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n",
      "1459\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Electrical'].value_counts())\n",
    "print(dataset['Electrical'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "dataset['Electrical'].fillna(value='SBrkr',inplace=True)\n",
    "print(dataset['Electrical'].count())\n",
    "missing_obj_col.remove('Electrical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979\n"
     ]
    }
   ],
   "source": [
    "mean=int(round(np.mean(dataset['GarageYrBlt'])))\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005.0    65\n",
      "2006.0    59\n",
      "2004.0    53\n",
      "2003.0    50\n",
      "2007.0    49\n",
      "          ..\n",
      "1908.0     1\n",
      "1927.0     1\n",
      "1933.0     1\n",
      "1900.0     1\n",
      "1906.0     1\n",
      "Name: GarageYrBlt, Length: 97, dtype: int64\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "print(dataset['GarageYrBlt'].value_counts())\n",
    "print(dataset['GarageYrBlt'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n"
     ]
    }
   ],
   "source": [
    "dataset['GarageYrBlt'].fillna(value=mean,inplace=True)\n",
    "print(dataset['GarageYrBlt'].count())\n",
    "missing_obj_col.remove('GarageYrBlt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alley',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_obj_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=dataset.count()\n",
    "N=dataset.shape[0]\n",
    "missing_col=[]\n",
    "for i in range(dataset.shape[1]):\n",
    "    if col[i]!=N:\n",
    "        missing_col.append(dataset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alley',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in missing_col:\n",
    "    dataset[col].fillna(value='NA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 0 to 359\n",
      "Data columns (total 80 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            1460 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1460 non-null object\n",
      "MasVnrArea       1460 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1460 non-null object\n",
      "BsmtCond         1460 non-null object\n",
      "BsmtExposure     1460 non-null object\n",
      "BsmtFinType1     1460 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1460 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1460 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      1460 non-null object\n",
      "GarageType       1460 non-null object\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageFinish     1460 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1460 non-null object\n",
      "GarageCond       1460 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           1460 non-null object\n",
      "Fence            1460 non-null object\n",
      "MiscFeature      1460 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Id'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 79)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
       "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
       "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
       "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
       "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=dataset.columns\n",
    "data_type=dataset.dtypes\n",
    "obj_cols=[]\n",
    "obj_cols.append(col[0])\n",
    "for i in range(dataset.shape[1]):\n",
    "    if data_type[i]=='object':\n",
    "        obj_cols.append(col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "dataset[obj_cols]=dataset[obj_cols].apply(le.fit_transform)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0           5         3         65.0     8450       1      1         3   \n",
       "1           0         3         80.0     9600       1      1         3   \n",
       "2           5         3         68.0    11250       1      1         0   \n",
       "3           6         3         60.0     9550       1      1         0   \n",
       "4           5         3         84.0    14260       1      1         0   \n",
       "5           4         3         85.0    14115       1      1         0   \n",
       "6           0         3         75.0    10084       1      1         3   \n",
       "\n",
       "   LandContour  Utilities  LotConfig  ...  ScreenPorch  PoolArea  PoolQC  \\\n",
       "0            3          0          4  ...            0         0       3   \n",
       "1            3          0          2  ...            0         0       3   \n",
       "2            3          0          4  ...            0         0       3   \n",
       "3            3          0          0  ...            0         0       3   \n",
       "4            3          0          2  ...            0         0       3   \n",
       "5            3          0          4  ...            0         0       3   \n",
       "6            3          0          4  ...            0         0       3   \n",
       "\n",
       "   Fence  MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0      4            1        0       2    2008         8              4  \n",
       "1      4            1        0       5    2007         8              4  \n",
       "2      4            1        0       9    2008         8              4  \n",
       "3      4            1        0       2    2006         8              0  \n",
       "4      4            1        0      12    2008         8              4  \n",
       "5      2            3      700      10    2009         8              4  \n",
       "6      4            1        0       8    2007         8              4  \n",
       "\n",
       "[7 rows x 79 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=dataset[:1100]\n",
    "x_test=dataset[1100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0              5         3         65.0     8450       1      1         3   \n",
      "1              0         3         80.0     9600       1      1         3   \n",
      "2              5         3         68.0    11250       1      1         0   \n",
      "3              6         3         60.0     9550       1      1         0   \n",
      "4              5         3         84.0    14260       1      1         0   \n",
      "...          ...       ...          ...      ...     ...    ...       ...   \n",
      "1095           0         3         78.0     9317       1      1         0   \n",
      "1096           6         4         60.0     6882       1      1         3   \n",
      "1097          11         3         70.0     3696       1      1         3   \n",
      "1098           4         4         50.0     6000       1      1         3   \n",
      "1099           0         3         82.0    11880       1      1         0   \n",
      "\n",
      "      LandContour  Utilities  LotConfig  ...  ScreenPorch  PoolArea  PoolQC  \\\n",
      "0               3          0          4  ...            0         0       3   \n",
      "1               3          0          2  ...            0         0       3   \n",
      "2               3          0          4  ...            0         0       3   \n",
      "3               3          0          0  ...            0         0       3   \n",
      "4               3          0          2  ...            0         0       3   \n",
      "...           ...        ...        ...  ...          ...       ...     ...   \n",
      "1095            3          0          4  ...            0         0       3   \n",
      "1096            3          0          4  ...            0         0       3   \n",
      "1097            3          0          4  ...            0         0       3   \n",
      "1098            3          0          4  ...            0         0       3   \n",
      "1099            3          0          4  ...            0         0       3   \n",
      "\n",
      "      Fence  MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0         4            1        0       2    2008         8              4  \n",
      "1         4            1        0       5    2007         8              4  \n",
      "2         4            1        0       9    2008         8              4  \n",
      "3         4            1        0       2    2006         8              0  \n",
      "4         4            1        0      12    2008         8              4  \n",
      "...     ...          ...      ...     ...     ...       ...            ...  \n",
      "1095      4            1        0       3    2007         8              4  \n",
      "1096      4            1        0       3    2007         8              4  \n",
      "1097      4            1        0      10    2007         8              4  \n",
      "1098      4            1        0       7    2009         8              4  \n",
      "1099      4            1        0       4    2009         0              0  \n",
      "\n",
      "[1100 rows x 79 columns]\n",
      "     MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
      "0             1         3         60.0     8400       1      1         3   \n",
      "1             0         3         61.0     9758       1      1         0   \n",
      "2             0         3         70.0     7000       1      1         3   \n",
      "3             0         3         79.0     8910       1      1         3   \n",
      "4            12         4         24.0     2016       1      1         3   \n",
      "..          ...       ...          ...      ...     ...    ...       ...   \n",
      "355           5         3         62.0     7917       1      1         3   \n",
      "356           0         3         85.0    13175       1      1         3   \n",
      "357           6         3         66.0     9042       1      1         3   \n",
      "358           0         3         68.0     9717       1      1         3   \n",
      "359           0         3         75.0     9937       1      1         3   \n",
      "\n",
      "     LandContour  Utilities  LotConfig  ...  ScreenPorch  PoolArea  PoolQC  \\\n",
      "0              0          0          4  ...            0         0       3   \n",
      "1              3          0          4  ...            0         0       3   \n",
      "2              3          0          4  ...            0         0       3   \n",
      "3              3          0          0  ...            0         0       3   \n",
      "4              3          0          4  ...            0         0       3   \n",
      "..           ...        ...        ...  ...          ...       ...     ...   \n",
      "355            3          0          4  ...            0         0       3   \n",
      "356            3          0          4  ...            0         0       3   \n",
      "357            3          0          4  ...            0         0       3   \n",
      "358            3          0          4  ...            0         0       3   \n",
      "359            3          0          4  ...            0         0       3   \n",
      "\n",
      "     Fence  MiscFeature  MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
      "0        4            1        0       1    2009         8              4  \n",
      "1        4            1        0       7    2007         8              4  \n",
      "2        3            1        0       4    2007         8              3  \n",
      "3        4            1        0       7    2006         8              4  \n",
      "4        4            1        0       4    2007         8              4  \n",
      "..     ...          ...      ...     ...     ...       ...            ...  \n",
      "355      4            1        0       8    2007         8              4  \n",
      "356      2            1        0       2    2010         8              4  \n",
      "357      0            3     2500       5    2010         8              4  \n",
      "358      4            1        0       4    2010         8              4  \n",
      "359      4            1        0       6    2008         8              4  \n",
      "\n",
      "[360 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       208500\n",
      "1       181500\n",
      "2       223500\n",
      "3       140000\n",
      "4       250000\n",
      "         ...  \n",
      "1095    176432\n",
      "1096    127000\n",
      "1097    170000\n",
      "1098    128000\n",
      "1099    157000\n",
      "Name: SalePrice, Length: 1100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(800,activation='relu',input_shape=(79,)))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 800)               64000     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 300)               240300    \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 390,691\n",
      "Trainable params: 390,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 220 samples\n",
      "Epoch 1/1000\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 39532278057.8909 - mae: 181747.1094 - val_loss: 33961756299.6364 - val_mae: 169549.6406\n",
      "Epoch 2/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 35600068756.9455 - mae: 171465.5781 - val_loss: 26900383967.4182 - val_mae: 148315.6250\n",
      "Epoch 3/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 23571294059.0545 - mae: 128944.4297 - val_loss: 7874863597.3818 - val_mae: 66280.4141\n",
      "Epoch 4/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 15286988753.4545 - mae: 61233.5820 - val_loss: 4125217266.0364 - val_mae: 43368.7617\n",
      "Epoch 5/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 10432448698.1818 - mae: 54452.4258 - val_loss: 5130855396.0727 - val_mae: 47905.2188\n",
      "Epoch 6/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 7512420528.8727 - mae: 52439.9766 - val_loss: 3556283154.6182 - val_mae: 39078.5625\n",
      "Epoch 7/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 5437358163.7818 - mae: 47330.2617 - val_loss: 3433971604.9455 - val_mae: 43354.5195\n",
      "Epoch 8/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 4608497375.4182 - mae: 45874.3398 - val_loss: 3205611701.5273 - val_mae: 37887.0352\n",
      "Epoch 9/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 3998042116.6545 - mae: 43749.0820 - val_loss: 3199480822.6909 - val_mae: 41218.4102\n",
      "Epoch 10/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 3716365130.4727 - mae: 44427.1094 - val_loss: 3009686085.8182 - val_mae: 37812.3984\n",
      "Epoch 11/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 3502257072.8727 - mae: 41932.4180 - val_loss: 3015774445.3818 - val_mae: 39544.3711\n",
      "Epoch 12/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 3330989884.5091 - mae: 42643.5781 - val_loss: 2954623902.2545 - val_mae: 39265.8320\n",
      "Epoch 13/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 3196484333.3818 - mae: 41128.4648 - val_loss: 2815219707.3455 - val_mae: 37486.9688\n",
      "Epoch 14/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 3070822283.6364 - mae: 39958.3711 - val_loss: 2746993696.5818 - val_mae: 37187.8359\n",
      "Epoch 15/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 2960963607.2727 - mae: 39560.3125 - val_loss: 2637730783.4182 - val_mae: 35974.3711\n",
      "Epoch 16/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 2824311789.3818 - mae: 38050.8828 - val_loss: 2592702440.7273 - val_mae: 36222.4531\n",
      "Epoch 17/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 2711030979.4909 - mae: 38013.0117 - val_loss: 2465608480.5818 - val_mae: 34737.8711\n",
      "Epoch 18/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 2590494592.0000 - mae: 36061.8320 - val_loss: 2401161714.0364 - val_mae: 34631.2734\n",
      "Epoch 19/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 2463236966.4000 - mae: 35865.8984 - val_loss: 2247545986.3273 - val_mae: 32470.8945\n",
      "Epoch 20/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 2360115521.1636 - mae: 33204.9883 - val_loss: 2231411456.0000 - val_mae: 33379.9922\n",
      "Epoch 21/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 2255284400.8727 - mae: 34684.7812 - val_loss: 2062639017.8909 - val_mae: 30913.8359\n",
      "Epoch 22/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 2147107369.8909 - mae: 30918.4141 - val_loss: 2047769216.0000 - val_mae: 31504.4414\n",
      "Epoch 23/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 2030928644.6545 - mae: 31567.7559 - val_loss: 1898052377.6000 - val_mae: 29192.9805\n",
      "Epoch 24/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1895015468.2182 - mae: 29225.2051 - val_loss: 1897333780.9455 - val_mae: 29854.8184\n",
      "Epoch 25/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1803773893.8182 - mae: 28458.4863 - val_loss: 1796872306.0364 - val_mae: 28487.4727\n",
      "Epoch 26/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 1767833120.5818 - mae: 27772.2559 - val_loss: 1775267016.1455 - val_mae: 28376.2480\n",
      "Epoch 27/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1738460748.8000 - mae: 28039.7227 - val_loss: 1696000465.4545 - val_mae: 27706.7949\n",
      "Epoch 28/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1654797770.4727 - mae: 26923.4551 - val_loss: 1821089470.8364 - val_mae: 29013.3633\n",
      "Epoch 29/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1661668207.7091 - mae: 26895.6250 - val_loss: 1669766665.3091 - val_mae: 27696.9941\n",
      "Epoch 30/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1613969098.4727 - mae: 26423.0469 - val_loss: 1659379954.0364 - val_mae: 27762.4883\n",
      "Epoch 31/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1596546443.6364 - mae: 26323.8379 - val_loss: 1696593526.6909 - val_mae: 27957.2949\n",
      "Epoch 32/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1585212616.1455 - mae: 26056.9023 - val_loss: 1635425701.2364 - val_mae: 27743.3145\n",
      "Epoch 33/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1616473604.6545 - mae: 26407.8652 - val_loss: 1657949684.3636 - val_mae: 27760.0977\n",
      "Epoch 34/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1604014114.9091 - mae: 26271.1914 - val_loss: 1657066077.0909 - val_mae: 27700.2441\n",
      "Epoch 35/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 1559786398.2545 - mae: 25801.3027 - val_loss: 1619891507.2000 - val_mae: 27556.6230\n",
      "Epoch 36/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1567069437.6727 - mae: 25998.2324 - val_loss: 1676848207.1273 - val_mae: 27727.0039\n",
      "Epoch 37/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1554290985.8909 - mae: 25764.3750 - val_loss: 1614901673.8909 - val_mae: 27428.5391\n",
      "Epoch 38/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1546793984.0000 - mae: 25596.9160 - val_loss: 1639432061.6727 - val_mae: 27526.0645\n",
      "Epoch 39/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1534847332.0727 - mae: 25584.7637 - val_loss: 1607945653.5273 - val_mae: 27462.0723\n",
      "Epoch 40/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 1542392880.8727 - mae: 25646.1094 - val_loss: 1636876662.6909 - val_mae: 27437.9121\n",
      "Epoch 41/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1546969871.1273 - mae: 25627.0156 - val_loss: 1612438290.6182 - val_mae: 27281.5098\n",
      "Epoch 42/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1542589009.4545 - mae: 25545.4180 - val_loss: 1623653590.1091 - val_mae: 27302.1562\n",
      "Epoch 43/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1516692794.1818 - mae: 25296.7598 - val_loss: 1621036099.4909 - val_mae: 27302.9531\n",
      "Epoch 44/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1521700194.9091 - mae: 25238.8379 - val_loss: 1620994613.5273 - val_mae: 27271.1270\n",
      "Epoch 45/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1521629030.4000 - mae: 25344.6660 - val_loss: 1591470806.1091 - val_mae: 27273.5957\n",
      "Epoch 46/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1584407994.1818 - mae: 26814.6055 - val_loss: 1861096119.8545 - val_mae: 29777.9727\n",
      "Epoch 47/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1610434096.8727 - mae: 26319.5957 - val_loss: 1723526797.9636 - val_mae: 29001.4043\n",
      "Epoch 48/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1785634643.7818 - mae: 27640.6914 - val_loss: 1603586825.3091 - val_mae: 27126.4727\n",
      "Epoch 49/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1665017204.3636 - mae: 27399.7812 - val_loss: 1742798673.4545 - val_mae: 28404.3906\n",
      "Epoch 50/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1539097600.0000 - mae: 26100.3008 - val_loss: 1696791919.7091 - val_mae: 28579.3496\n",
      "Epoch 51/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1617657830.4000 - mae: 26782.9570 - val_loss: 1799010178.3273 - val_mae: 29036.6504\n",
      "Epoch 52/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1535854224.2909 - mae: 26283.7246 - val_loss: 1612892187.9273 - val_mae: 27354.9277\n",
      "Epoch 53/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 1591852381.0909 - mae: 25886.5957 - val_loss: 1579284128.5818 - val_mae: 26853.3770\n",
      "Epoch 54/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 1557074014.2545 - mae: 25664.1641 - val_loss: 1777139018.4727 - val_mae: 28750.7637\n",
      "Epoch 55/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1563337025.1636 - mae: 25976.9473 - val_loss: 1614169555.7818 - val_mae: 27356.1758\n",
      "Epoch 56/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1530488431.7091 - mae: 25397.1582 - val_loss: 1610296603.9273 - val_mae: 26973.8594\n",
      "Epoch 57/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1464477837.9636 - mae: 24742.2363 - val_loss: 1577152118.6909 - val_mae: 26804.5684\n",
      "Epoch 58/1000\n",
      "880/880 [==============================] - 0s 61us/step - loss: 1463538790.4000 - mae: 24876.1094 - val_loss: 1701265847.8545 - val_mae: 27921.3809\n",
      "Epoch 59/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1526669444.6545 - mae: 25324.0645 - val_loss: 1582597755.3455 - val_mae: 26916.2051\n",
      "Epoch 60/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1509418658.9091 - mae: 25132.0508 - val_loss: 1580939224.4364 - val_mae: 26772.9395\n",
      "Epoch 61/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 1466452082.0364 - mae: 24755.3203 - val_loss: 1589320103.5636 - val_mae: 26789.9023\n",
      "Epoch 62/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1464415780.0727 - mae: 24722.4707 - val_loss: 1585261779.7818 - val_mae: 27025.8926\n",
      "Epoch 63/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1455731239.5636 - mae: 24953.0293 - val_loss: 1681668489.3091 - val_mae: 27724.4902\n",
      "Epoch 64/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1473238932.9455 - mae: 24985.3047 - val_loss: 1571843137.1636 - val_mae: 26785.7930\n",
      "Epoch 65/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1473865005.3818 - mae: 25184.2676 - val_loss: 1788090321.4545 - val_mae: 28958.8867\n",
      "Epoch 66/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1454486290.6182 - mae: 24841.0234 - val_loss: 1592304751.7091 - val_mae: 27094.9902\n",
      "Epoch 67/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 1499349285.2364 - mae: 25357.2871 - val_loss: 1630958561.7455 - val_mae: 27209.6250\n",
      "Epoch 68/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1458494531.4909 - mae: 24839.4277 - val_loss: 1560361062.4000 - val_mae: 26564.7637\n",
      "Epoch 69/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1433392999.5636 - mae: 24310.2695 - val_loss: 1593694892.2182 - val_mae: 26775.2246\n",
      "Epoch 70/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1480211674.7636 - mae: 24569.0820 - val_loss: 1610009802.4727 - val_mae: 26965.1367\n",
      "Epoch 71/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1439537757.0909 - mae: 24415.3477 - val_loss: 1575343429.8182 - val_mae: 26600.4043\n",
      "Epoch 72/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1436667848.1455 - mae: 24262.3457 - val_loss: 1558927634.6182 - val_mae: 26431.2051\n",
      "Epoch 73/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1483908061.0909 - mae: 24951.6133 - val_loss: 1694001014.6909 - val_mae: 27858.4297\n",
      "Epoch 74/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1479751347.2000 - mae: 24507.3926 - val_loss: 1561572354.3273 - val_mae: 26375.5684\n",
      "Epoch 75/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1418605817.0182 - mae: 24103.9824 - val_loss: 1611069533.0909 - val_mae: 26930.8789\n",
      "Epoch 76/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1423285601.7455 - mae: 24299.1348 - val_loss: 1568583254.1091 - val_mae: 26469.2461\n",
      "Epoch 77/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1419091654.9818 - mae: 24235.4863 - val_loss: 1550050976.5818 - val_mae: 26342.3320\n",
      "Epoch 78/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 1419720402.6182 - mae: 24434.0938 - val_loss: 1657808770.3273 - val_mae: 27474.4902\n",
      "Epoch 79/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1449945968.8727 - mae: 24434.4805 - val_loss: 1554528200.1455 - val_mae: 26440.6504\n",
      "Epoch 80/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1417596950.1091 - mae: 24332.6445 - val_loss: 1568762910.2545 - val_mae: 26468.2949\n",
      "Epoch 81/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1421730734.5455 - mae: 24213.4766 - val_loss: 1619401248.5818 - val_mae: 27043.9004\n",
      "Epoch 82/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1413510569.8909 - mae: 24138.1797 - val_loss: 1562155110.4000 - val_mae: 26632.1367\n",
      "Epoch 83/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1480608807.5636 - mae: 25250.8770 - val_loss: 1703954785.7455 - val_mae: 28060.6406\n",
      "Epoch 84/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1444429465.6000 - mae: 24724.0645 - val_loss: 1556924509.0909 - val_mae: 26355.1582\n",
      "Epoch 85/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1446611667.7818 - mae: 24524.0312 - val_loss: 1610551286.6909 - val_mae: 27351.2402\n",
      "Epoch 86/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1447727697.4545 - mae: 24932.1055 - val_loss: 1752821832.1455 - val_mae: 28669.0000\n",
      "Epoch 87/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1406441660.5091 - mae: 24731.7949 - val_loss: 1558626432.0000 - val_mae: 26545.9492\n",
      "Epoch 88/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1414936932.0727 - mae: 23874.9746 - val_loss: 1547026732.2182 - val_mae: 26247.6250\n",
      "Epoch 89/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1403302988.8000 - mae: 23917.6094 - val_loss: 1605707126.6909 - val_mae: 26914.0703\n",
      "Epoch 90/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1424256548.0727 - mae: 24062.9590 - val_loss: 1618112868.0727 - val_mae: 27038.0879\n",
      "Epoch 91/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1412248502.6909 - mae: 24106.4824 - val_loss: 1563838673.4545 - val_mae: 26562.5703\n",
      "Epoch 92/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1478697290.4727 - mae: 24862.7324 - val_loss: 1533529825.7455 - val_mae: 26040.4277\n",
      "Epoch 93/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1395235353.6000 - mae: 23919.8477 - val_loss: 1575556929.1636 - val_mae: 26525.0977\n",
      "Epoch 94/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1388840925.0909 - mae: 23944.5098 - val_loss: 1530040864.5818 - val_mae: 26013.6680\n",
      "Epoch 95/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 1406609391.7091 - mae: 24082.7051 - val_loss: 1529897385.8909 - val_mae: 26079.3359\n",
      "Epoch 96/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1423611035.9273 - mae: 24982.3984 - val_loss: 1792518784.0000 - val_mae: 29207.6992\n",
      "Epoch 97/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1454808552.7273 - mae: 24291.6055 - val_loss: 1529882603.0545 - val_mae: 26049.5430\n",
      "Epoch 98/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1385513222.9818 - mae: 24019.9082 - val_loss: 1526878738.6182 - val_mae: 25975.4766\n",
      "Epoch 99/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1393199759.1273 - mae: 24241.6348 - val_loss: 1740994585.6000 - val_mae: 28612.2500\n",
      "Epoch 100/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1532532056.4364 - mae: 25639.4863 - val_loss: 1573645170.0364 - val_mae: 26816.4629\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 65us/step - loss: 1432299919.1273 - mae: 24883.0410 - val_loss: 1532349186.3273 - val_mae: 25980.6016\n",
      "Epoch 102/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1467900169.3091 - mae: 25187.2871 - val_loss: 1776015090.0364 - val_mae: 28973.3008\n",
      "Epoch 103/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1459541033.8909 - mae: 24978.4863 - val_loss: 1560493689.0182 - val_mae: 26537.0859\n",
      "Epoch 104/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 1368689228.8000 - mae: 24057.5918 - val_loss: 1592359633.4545 - val_mae: 26718.7598\n",
      "Epoch 105/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1382203674.7636 - mae: 23864.6855 - val_loss: 1545029289.8909 - val_mae: 26139.0566\n",
      "Epoch 106/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1360002127.1273 - mae: 23652.2188 - val_loss: 1517528627.2000 - val_mae: 25889.7090\n",
      "Epoch 107/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1373597195.6364 - mae: 24006.4492 - val_loss: 1698202426.1818 - val_mae: 28036.5781\n",
      "Epoch 108/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1347267146.4727 - mae: 23952.3613 - val_loss: 1525766039.2727 - val_mae: 26059.5879\n",
      "Epoch 109/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1377091167.4182 - mae: 23639.3066 - val_loss: 1513944813.3818 - val_mae: 25810.7129\n",
      "Epoch 110/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1346122775.2727 - mae: 23201.0273 - val_loss: 1519517232.8727 - val_mae: 25882.2734\n",
      "Epoch 111/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1349246974.8364 - mae: 23648.7676 - val_loss: 1591322198.1091 - val_mae: 26747.3418\n",
      "Epoch 112/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1363420256.5818 - mae: 23362.0195 - val_loss: 1552717405.0909 - val_mae: 26208.6367\n",
      "Epoch 113/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1335402240.0000 - mae: 23179.3438 - val_loss: 1521308020.3636 - val_mae: 25921.0859\n",
      "Epoch 114/1000\n",
      "880/880 [==============================] - 0s 89us/step - loss: 1419188350.8364 - mae: 24006.0508 - val_loss: 1511926413.9636 - val_mae: 25764.4180\n",
      "Epoch 115/1000\n",
      "880/880 [==============================] - 0s 91us/step - loss: 1470552801.7455 - mae: 24502.4824 - val_loss: 1610626741.5273 - val_mae: 26975.2090\n",
      "Epoch 116/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1472431640.4364 - mae: 25049.1055 - val_loss: 1786547851.6364 - val_mae: 29246.9551\n",
      "Epoch 117/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1466962378.4727 - mae: 25322.7598 - val_loss: 1565085160.7273 - val_mae: 26628.5176\n",
      "Epoch 118/1000\n",
      "880/880 [==============================] - 0s 84us/step - loss: 1405076985.0182 - mae: 24613.9902 - val_loss: 1509003410.6182 - val_mae: 25670.1777\n",
      "Epoch 119/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1349918588.5091 - mae: 23443.7188 - val_loss: 1514869257.3091 - val_mae: 25785.8105\n",
      "Epoch 120/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1321508298.4727 - mae: 23114.4746 - val_loss: 1515095945.3091 - val_mae: 25809.6230\n",
      "Epoch 121/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1337367652.0727 - mae: 23313.4746 - val_loss: 1513235483.9273 - val_mae: 25842.4219\n",
      "Epoch 122/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1366521246.2545 - mae: 23595.7539 - val_loss: 1502716699.9273 - val_mae: 25660.3105\n",
      "Epoch 123/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1318551656.7273 - mae: 23146.0957 - val_loss: 1524190333.6727 - val_mae: 25925.1777\n",
      "Epoch 124/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1320087112.1455 - mae: 23107.0918 - val_loss: 1530750280.1455 - val_mae: 25977.8223\n",
      "Epoch 125/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1347552506.1818 - mae: 23353.4160 - val_loss: 1542873022.8364 - val_mae: 26484.5703\n",
      "Epoch 126/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1394313477.8182 - mae: 24093.2344 - val_loss: 1499639901.0909 - val_mae: 25620.5371\n",
      "Epoch 127/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1309752380.5091 - mae: 23160.2305 - val_loss: 1549453118.8364 - val_mae: 26214.5781\n",
      "Epoch 128/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1318565484.2182 - mae: 23349.0469 - val_loss: 1494859471.1273 - val_mae: 25635.2910\n",
      "Epoch 129/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1302907303.5636 - mae: 23095.0840 - val_loss: 1625377079.8545 - val_mae: 27205.9434\n",
      "Epoch 130/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1355527649.7455 - mae: 23205.2520 - val_loss: 1563643310.5455 - val_mae: 26409.8203\n",
      "Epoch 131/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1304638920.1455 - mae: 23291.3379 - val_loss: 1513740530.0364 - val_mae: 26017.2676\n",
      "Epoch 132/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1356605758.8364 - mae: 23719.8652 - val_loss: 1527647194.7636 - val_mae: 25958.0723\n",
      "Epoch 133/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1282271865.0182 - mae: 23051.2754 - val_loss: 1497646163.7818 - val_mae: 25670.6719\n",
      "Epoch 134/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1335833772.2182 - mae: 23181.6992 - val_loss: 1488643977.3091 - val_mae: 25505.0332\n",
      "Epoch 135/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1295082539.0545 - mae: 22902.2891 - val_loss: 1526606764.2182 - val_mae: 26001.9570\n",
      "Epoch 136/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1295496043.0545 - mae: 22792.3223 - val_loss: 1547737120.5818 - val_mae: 26267.1230\n",
      "Epoch 137/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1316326418.6182 - mae: 23106.3066 - val_loss: 1534901848.4364 - val_mae: 26070.2227\n",
      "Epoch 138/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1305824544.5818 - mae: 22922.6621 - val_loss: 1526448358.4000 - val_mae: 26277.0820\n",
      "Epoch 139/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1413527710.2545 - mae: 24321.8105 - val_loss: 1505159849.8909 - val_mae: 25705.2910\n",
      "Epoch 140/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1381273690.7636 - mae: 24435.9609 - val_loss: 1659180357.8182 - val_mae: 27654.5996\n",
      "Epoch 141/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1310095834.7636 - mae: 23459.6777 - val_loss: 1481007087.7091 - val_mae: 25400.3496\n",
      "Epoch 142/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1304042365.6727 - mae: 22881.5781 - val_loss: 1483258954.4727 - val_mae: 25403.3984\n",
      "Epoch 143/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 1283427744.5818 - mae: 22835.9004 - val_loss: 1506388149.5273 - val_mae: 25690.3027\n",
      "Epoch 144/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 1300303633.4545 - mae: 22957.4551 - val_loss: 1536981869.3818 - val_mae: 26135.1641\n",
      "Epoch 145/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 1294007238.9818 - mae: 22823.5781 - val_loss: 1549585487.1273 - val_mae: 26282.0645\n",
      "Epoch 146/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1312525360.8727 - mae: 23382.5312 - val_loss: 1476925244.5091 - val_mae: 25421.7129\n",
      "Epoch 147/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1288185579.0545 - mae: 22755.0449 - val_loss: 1479245477.2364 - val_mae: 25421.1289\n",
      "Epoch 148/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 1320453380.6545 - mae: 23262.8496 - val_loss: 1475431270.4000 - val_mae: 25347.4688\n",
      "Epoch 149/1000\n",
      "880/880 [==============================] - 0s 91us/step - loss: 1392478238.2545 - mae: 24309.3223 - val_loss: 1804224863.4182 - val_mae: 29565.8223\n",
      "Epoch 150/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1397064192.0000 - mae: 24549.3301 - val_loss: 1485238669.9636 - val_mae: 25399.0879\n",
      "Epoch 151/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1310226706.6182 - mae: 23225.1699 - val_loss: 1476037438.8364 - val_mae: 25417.9844\n",
      "Epoch 152/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1303514023.5636 - mae: 22804.5684 - val_loss: 1498767830.1091 - val_mae: 25655.2461\n",
      "Epoch 153/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1331687835.9273 - mae: 23385.0098 - val_loss: 1501564260.0727 - val_mae: 25680.1309\n",
      "Epoch 154/1000\n",
      "880/880 [==============================] - 0s 61us/step - loss: 1287776176.8727 - mae: 23124.4355 - val_loss: 1480839372.8000 - val_mae: 25554.0312\n",
      "Epoch 155/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1298584340.9455 - mae: 22751.8789 - val_loss: 1468967410.0364 - val_mae: 25287.8594\n",
      "Epoch 156/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1269073296.2909 - mae: 22677.9121 - val_loss: 1477504551.5636 - val_mae: 25329.4082\n",
      "Epoch 157/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1278073944.4364 - mae: 22816.5137 - val_loss: 1474922472.7273 - val_mae: 25479.3945\n",
      "Epoch 158/1000\n",
      "880/880 [==============================] - 0s 88us/step - loss: 1309022145.1636 - mae: 23000.4473 - val_loss: 1474847934.8364 - val_mae: 25477.9883\n",
      "Epoch 159/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1254404075.0545 - mae: 22688.4004 - val_loss: 1564248273.4545 - val_mae: 26526.6758\n",
      "Epoch 160/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 1313261049.0182 - mae: 22977.8320 - val_loss: 1495284552.1455 - val_mae: 25605.0859\n",
      "Epoch 161/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1268338587.9273 - mae: 22618.2480 - val_loss: 1477662517.5273 - val_mae: 25337.5000\n",
      "Epoch 162/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1256869669.2364 - mae: 22840.1797 - val_loss: 1496112581.8182 - val_mae: 26023.2070\n",
      "Epoch 163/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1343297627.9273 - mae: 24425.1797 - val_loss: 1562256253.6727 - val_mae: 26521.9551\n",
      "Epoch 164/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1289742910.8364 - mae: 23417.1055 - val_loss: 1527754952.1455 - val_mae: 26095.0859\n",
      "Epoch 165/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1294577221.8182 - mae: 22833.9629 - val_loss: 1463173124.6545 - val_mae: 25297.7500\n",
      "Epoch 166/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1270987802.7636 - mae: 22519.1250 - val_loss: 1453044289.1636 - val_mae: 25117.6367\n",
      "Epoch 167/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1263054702.5455 - mae: 22455.0703 - val_loss: 1464774202.1818 - val_mae: 25179.2129\n",
      "Epoch 168/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1259080381.6727 - mae: 22479.2305 - val_loss: 1462170663.5636 - val_mae: 25169.1719\n",
      "Epoch 169/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1241727953.4545 - mae: 22366.6582 - val_loss: 1461042480.8727 - val_mae: 25124.7910\n",
      "Epoch 170/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1271402326.1091 - mae: 23081.9062 - val_loss: 1625165737.8909 - val_mae: 27232.0605\n",
      "Epoch 171/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1285683977.3091 - mae: 23038.6621 - val_loss: 1495405377.1636 - val_mae: 25596.0371\n",
      "Epoch 172/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1270650151.5636 - mae: 22741.5391 - val_loss: 1460833952.5818 - val_mae: 25382.4004\n",
      "Epoch 173/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 1213431909.2364 - mae: 22581.7793 - val_loss: 1656293885.6727 - val_mae: 27708.5371\n",
      "Epoch 174/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1273527600.8727 - mae: 23087.7168 - val_loss: 1459161565.0909 - val_mae: 25115.8652\n",
      "Epoch 175/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1314889369.6000 - mae: 23913.8574 - val_loss: 1537963257.0182 - val_mae: 26654.6055\n",
      "Epoch 176/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1311232704.0000 - mae: 24484.0254 - val_loss: 1511297417.3091 - val_mae: 25819.9473\n",
      "Epoch 177/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1286853607.5636 - mae: 22968.1680 - val_loss: 1536323439.7091 - val_mae: 26090.9746\n",
      "Epoch 178/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1240671753.3091 - mae: 22688.2871 - val_loss: 1468961829.2364 - val_mae: 25551.6094\n",
      "Epoch 179/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1240591897.6000 - mae: 22990.7324 - val_loss: 1529394857.8909 - val_mae: 26056.6309\n",
      "Epoch 180/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1218576795.9273 - mae: 22346.6562 - val_loss: 1441884399.7091 - val_mae: 25069.1914\n",
      "Epoch 181/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1253213830.9818 - mae: 22332.6074 - val_loss: 1441631909.2364 - val_mae: 25008.9355\n",
      "Epoch 182/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1218577226.4727 - mae: 22305.5879 - val_loss: 1513231764.9455 - val_mae: 25918.3320\n",
      "Epoch 183/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1275360749.3818 - mae: 22955.0605 - val_loss: 1599682995.2000 - val_mae: 26961.5312\n",
      "Epoch 184/1000\n",
      "880/880 [==============================] - 0s 62us/step - loss: 1236095201.7455 - mae: 22547.7676 - val_loss: 1439293586.6182 - val_mae: 24962.7363\n",
      "Epoch 185/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1199718046.2545 - mae: 22207.0430 - val_loss: 1558483472.2909 - val_mae: 26465.5039\n",
      "Epoch 186/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1229035739.9273 - mae: 22779.3438 - val_loss: 1435116038.9818 - val_mae: 25024.4844\n",
      "Epoch 187/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1236317514.4727 - mae: 22405.4590 - val_loss: 1460670391.8545 - val_mae: 25601.7129\n",
      "Epoch 188/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1377737662.8364 - mae: 24864.4473 - val_loss: 1558600166.4000 - val_mae: 26467.2637\n",
      "Epoch 189/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1205542704.8727 - mae: 22231.5859 - val_loss: 1430515092.9455 - val_mae: 24897.5859\n",
      "Epoch 190/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1215101938.0364 - mae: 22148.1836 - val_loss: 1433230738.6182 - val_mae: 25066.0273\n",
      "Epoch 191/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1217987561.8909 - mae: 22530.4863 - val_loss: 1668129591.8545 - val_mae: 27909.9707\n",
      "Epoch 192/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1299073280.0000 - mae: 23567.9727 - val_loss: 1469833290.4727 - val_mae: 25315.3145\n",
      "Epoch 193/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1244145377.7455 - mae: 22037.8359 - val_loss: 1454956697.6000 - val_mae: 25083.0918\n",
      "Epoch 194/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1226127506.6182 - mae: 22471.3594 - val_loss: 1456763350.1091 - val_mae: 25073.0410\n",
      "Epoch 195/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1215646191.7091 - mae: 22494.2109 - val_loss: 1640459461.8182 - val_mae: 27441.9609\n",
      "Epoch 196/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1293380703.4182 - mae: 23160.0410 - val_loss: 1454802515.7818 - val_mae: 25068.1719\n",
      "Epoch 197/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1234591441.4545 - mae: 22822.4961 - val_loss: 1452958284.8000 - val_mae: 25339.9551\n",
      "Epoch 198/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1243727967.4182 - mae: 22502.4980 - val_loss: 1444841932.8000 - val_mae: 25208.7773\n",
      "Epoch 199/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 1206572428.8000 - mae: 22571.2520 - val_loss: 1678325152.5818 - val_mae: 27995.8379\n",
      "Epoch 200/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1241296258.3273 - mae: 22888.0547 - val_loss: 1439136581.8182 - val_mae: 25287.1504\n",
      "Epoch 201/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 75us/step - loss: 1241130203.9273 - mae: 22869.5059 - val_loss: 1456072131.4909 - val_mae: 25468.4219\n",
      "Epoch 202/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1256409618.6182 - mae: 22601.4414 - val_loss: 1429028740.6545 - val_mae: 24846.6816\n",
      "Epoch 203/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 1271156964.0727 - mae: 23120.2441 - val_loss: 1464506761.3091 - val_mae: 25232.6953\n",
      "Epoch 204/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1193841259.0545 - mae: 22063.3418 - val_loss: 1432080558.5455 - val_mae: 24757.9824\n",
      "Epoch 205/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1180347382.6909 - mae: 21856.1855 - val_loss: 1469895347.2000 - val_mae: 25285.0117\n",
      "Epoch 206/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1172819386.1818 - mae: 21843.6699 - val_loss: 1426372338.0364 - val_mae: 24917.8945\n",
      "Epoch 207/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1229824907.6364 - mae: 22687.4473 - val_loss: 1422222336.0000 - val_mae: 24820.1836\n",
      "Epoch 208/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1213883124.3636 - mae: 22752.6309 - val_loss: 1738241924.6545 - val_mae: 28807.7363\n",
      "Epoch 209/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1375214086.9818 - mae: 24356.8652 - val_loss: 1457713349.8182 - val_mae: 25106.3691\n",
      "Epoch 210/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1273040047.7091 - mae: 23557.3320 - val_loss: 1437132367.1273 - val_mae: 25025.8496\n",
      "Epoch 211/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1184645807.7091 - mae: 22112.4941 - val_loss: 1456462075.3455 - val_mae: 24938.7949\n",
      "Epoch 212/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1222172769.7455 - mae: 22713.8926 - val_loss: 1540219566.5455 - val_mae: 26089.4570\n",
      "Epoch 213/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1379720946.0364 - mae: 24818.4141 - val_loss: 1662536741.2364 - val_mae: 28383.6426\n",
      "Epoch 214/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1321587124.3636 - mae: 24000.4961 - val_loss: 1426534120.7273 - val_mae: 24777.0586\n",
      "Epoch 215/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1264450243.4909 - mae: 23647.6543 - val_loss: 1806731387.3455 - val_mae: 29726.2695\n",
      "Epoch 216/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1226078494.2545 - mae: 22928.2109 - val_loss: 1420784041.8909 - val_mae: 24853.5371\n",
      "Epoch 217/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1183002741.5273 - mae: 22328.2637 - val_loss: 1442697590.6909 - val_mae: 24832.1133\n",
      "Epoch 218/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 1184416706.3273 - mae: 21932.4199 - val_loss: 1442625924.6545 - val_mae: 24895.9180\n",
      "Epoch 219/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1168483787.6364 - mae: 21846.5371 - val_loss: 1436872901.8182 - val_mae: 24824.7930\n",
      "Epoch 220/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1192979138.3273 - mae: 22096.9727 - val_loss: 1423793082.1818 - val_mae: 24877.7949\n",
      "Epoch 221/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1217807618.3273 - mae: 22744.5000 - val_loss: 1430250086.4000 - val_mae: 25057.1914\n",
      "Epoch 222/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1348852092.5091 - mae: 24689.6309 - val_loss: 1651541208.4364 - val_mae: 27705.5000\n",
      "Epoch 223/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1230839221.5273 - mae: 23249.6230 - val_loss: 1437416950.6909 - val_mae: 24824.3027\n",
      "Epoch 224/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1249149230.5455 - mae: 22636.2559 - val_loss: 1409467350.1091 - val_mae: 24555.9219\n",
      "Epoch 225/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1169355481.6000 - mae: 21723.9180 - val_loss: 1421082640.2909 - val_mae: 24578.0039\n",
      "Epoch 226/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1165215958.1091 - mae: 21757.9727 - val_loss: 1524180340.3636 - val_mae: 25984.9043\n",
      "Epoch 227/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1196409895.5636 - mae: 22198.0879 - val_loss: 1478032577.1636 - val_mae: 25296.3848\n",
      "Epoch 228/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1157598687.4182 - mae: 21936.5410 - val_loss: 1402928730.7636 - val_mae: 24525.4980\n",
      "Epoch 229/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1166871768.4364 - mae: 21753.8145 - val_loss: 1505070827.0545 - val_mae: 25781.2773\n",
      "Epoch 230/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1166753284.6545 - mae: 21749.4863 - val_loss: 1397905743.1273 - val_mae: 24464.1914\n",
      "Epoch 231/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1135608288.5818 - mae: 21768.0957 - val_loss: 1562712150.1091 - val_mae: 26459.4766\n",
      "Epoch 232/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1225263291.3455 - mae: 22324.7832 - val_loss: 1562209165.9636 - val_mae: 26440.6816\n",
      "Epoch 233/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1169264821.5273 - mae: 22105.6191 - val_loss: 1400410870.6909 - val_mae: 24496.2266\n",
      "Epoch 234/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1158480393.3091 - mae: 21719.8730 - val_loss: 1400292163.4909 - val_mae: 24434.2871\n",
      "Epoch 235/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1135694459.3455 - mae: 21654.7441 - val_loss: 1427144468.9455 - val_mae: 24770.4531\n",
      "Epoch 236/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1113516329.8909 - mae: 21729.0508 - val_loss: 1495650846.2545 - val_mae: 26313.1289\n",
      "Epoch 237/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1263110171.9273 - mae: 24047.7559 - val_loss: 1692897275.3455 - val_mae: 28320.5547\n",
      "Epoch 238/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1158988639.4182 - mae: 22531.3555 - val_loss: 1391984356.0727 - val_mae: 24319.9531\n",
      "Epoch 239/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1146082534.4000 - mae: 21617.6191 - val_loss: 1386226413.3818 - val_mae: 24345.6094\n",
      "Epoch 240/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1138343909.2364 - mae: 21401.9883 - val_loss: 1424648508.5091 - val_mae: 24668.7637\n",
      "Epoch 241/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1117996474.1818 - mae: 21390.3105 - val_loss: 1389035506.0364 - val_mae: 24345.6152\n",
      "Epoch 242/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 1172689666.3273 - mae: 22503.5703 - val_loss: 1528575387.9273 - val_mae: 26077.1855\n",
      "Epoch 243/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1186056450.3273 - mae: 22348.3457 - val_loss: 1462853792.5818 - val_mae: 25144.6055\n",
      "Epoch 244/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1243717978.7636 - mae: 22817.4609 - val_loss: 1554211881.8909 - val_mae: 26426.1719\n",
      "Epoch 245/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1183883628.2182 - mae: 22974.1191 - val_loss: 1439996227.4909 - val_mae: 25447.1289\n",
      "Epoch 246/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1190008484.0727 - mae: 22120.6797 - val_loss: 1399907430.4000 - val_mae: 24729.9277\n",
      "Epoch 247/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1244458610.0364 - mae: 23003.7266 - val_loss: 1413797487.7091 - val_mae: 24497.9453\n",
      "Epoch 248/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1224462571.0545 - mae: 23563.8750 - val_loss: 1920670077.6727 - val_mae: 31458.3457\n",
      "Epoch 249/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1246517154.9091 - mae: 23930.3926 - val_loss: 1433508198.4000 - val_mae: 25317.9590\n",
      "Epoch 250/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1120647270.4000 - mae: 22252.0039 - val_loss: 1410543906.9091 - val_mae: 24469.8770\n",
      "Epoch 251/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1116274206.2545 - mae: 21600.5801 - val_loss: 1465162235.3455 - val_mae: 25180.8301\n",
      "Epoch 252/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1130677657.6000 - mae: 22099.2090 - val_loss: 1424781477.2364 - val_mae: 25008.4824\n",
      "Epoch 253/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1171259742.2545 - mae: 22291.4609 - val_loss: 1396237332.9455 - val_mae: 24459.9395\n",
      "Epoch 254/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1181558306.9091 - mae: 22901.7676 - val_loss: 1712112304.8727 - val_mae: 28567.1445\n",
      "Epoch 255/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 1196648820.3636 - mae: 23223.4727 - val_loss: 1431473291.6364 - val_mae: 24727.5723\n",
      "Epoch 256/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1126877590.1091 - mae: 22073.5547 - val_loss: 1601344963.4909 - val_mae: 27837.4004\n",
      "Epoch 257/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1287810304.0000 - mae: 24149.0566 - val_loss: 1380787500.2182 - val_mae: 24051.1523\n",
      "Epoch 258/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1160681260.2182 - mae: 22812.7500 - val_loss: 1749978179.4909 - val_mae: 29205.2227\n",
      "Epoch 259/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1251962372.6545 - mae: 23576.1270 - val_loss: 1379245630.8364 - val_mae: 24142.9082\n",
      "Epoch 260/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1188336669.0909 - mae: 22137.6504 - val_loss: 1385557885.6727 - val_mae: 24303.9629\n",
      "Epoch 261/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1117372665.0182 - mae: 21912.3008 - val_loss: 1414824603.9273 - val_mae: 24532.1855\n",
      "Epoch 262/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1088768576.0000 - mae: 21247.9434 - val_loss: 1396209082.1818 - val_mae: 24362.0312\n",
      "Epoch 263/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1099726170.7636 - mae: 21462.6387 - val_loss: 1428998765.3818 - val_mae: 24752.5137\n",
      "Epoch 264/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1122075550.2545 - mae: 21556.1953 - val_loss: 1474895588.0727 - val_mae: 25391.4023\n",
      "Epoch 265/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1124213933.3818 - mae: 21853.9492 - val_loss: 1370183770.7636 - val_mae: 24041.7539\n",
      "Epoch 266/1000\n",
      "880/880 [==============================] - 0s 97us/step - loss: 1123236666.1818 - mae: 21470.8457 - val_loss: 1372217413.8182 - val_mae: 24321.9121\n",
      "Epoch 267/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1092326711.8545 - mae: 21439.3926 - val_loss: 1361667523.4909 - val_mae: 24037.4453\n",
      "Epoch 268/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1143564034.3273 - mae: 21964.4863 - val_loss: 1462003323.3455 - val_mae: 25193.4180\n",
      "Epoch 269/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1116777209.0182 - mae: 21869.2441 - val_loss: 1514636704.5818 - val_mae: 25950.2910\n",
      "Epoch 270/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1091498164.9455 - mae: 21515.7773 - val_loss: 1360994874.1818 - val_mae: 23946.0957\n",
      "Epoch 271/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1080036824.4364 - mae: 21083.4199 - val_loss: 1361489687.2727 - val_mae: 23910.5410\n",
      "Epoch 272/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1068361496.4364 - mae: 21128.6387 - val_loss: 1581092182.1091 - val_mae: 26869.0547\n",
      "Epoch 273/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1166767526.4000 - mae: 22616.7695 - val_loss: 1388494715.3455 - val_mae: 24225.1367\n",
      "Epoch 274/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1196465922.3273 - mae: 23011.6133 - val_loss: 1484821171.2000 - val_mae: 26337.9453\n",
      "Epoch 275/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1162937701.2364 - mae: 22383.1191 - val_loss: 1382644505.6000 - val_mae: 24401.4863\n",
      "Epoch 276/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1108779513.0182 - mae: 21412.6914 - val_loss: 1400754978.9091 - val_mae: 24257.9590\n",
      "Epoch 277/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1076287254.1091 - mae: 21194.0547 - val_loss: 1465174330.1818 - val_mae: 25302.5957\n",
      "Epoch 278/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1093742237.0909 - mae: 21954.1406 - val_loss: 1364627102.2545 - val_mae: 23922.7871\n",
      "Epoch 279/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1097424916.9455 - mae: 21191.6445 - val_loss: 1374857390.5455 - val_mae: 23886.9004\n",
      "Epoch 280/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1059221510.9818 - mae: 20926.4727 - val_loss: 1372826377.3091 - val_mae: 23937.7090\n",
      "Epoch 281/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1060159911.5636 - mae: 21254.9766 - val_loss: 1388892550.9818 - val_mae: 24876.5273\n",
      "Epoch 282/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1111424026.1818 - mae: 21783.1543 - val_loss: 1349742121.8909 - val_mae: 23849.4082\n",
      "Epoch 283/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1088358928.2909 - mae: 21584.3809 - val_loss: 1360561684.9455 - val_mae: 23788.9004\n",
      "Epoch 284/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1065759143.5636 - mae: 20987.2031 - val_loss: 1366504459.6364 - val_mae: 24446.9902\n",
      "Epoch 285/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1152382740.9455 - mae: 22008.5293 - val_loss: 1357372823.2727 - val_mae: 23903.7695\n",
      "Epoch 286/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1372725227.0545 - mae: 25224.2656 - val_loss: 1512325638.9818 - val_mae: 26008.6758\n",
      "Epoch 287/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1351822191.7091 - mae: 24783.7656 - val_loss: 1879346404.0727 - val_mae: 30862.8457\n",
      "Epoch 288/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1181641555.7818 - mae: 23918.2090 - val_loss: 1344332383.4182 - val_mae: 23961.0723\n",
      "Epoch 289/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 1118507008.0000 - mae: 21842.3633 - val_loss: 1426580335.7091 - val_mae: 25312.3457\n",
      "Epoch 290/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1254921992.1455 - mae: 23331.8945 - val_loss: 1337226093.3818 - val_mae: 23609.5098\n",
      "Epoch 291/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1125890222.5455 - mae: 21871.1855 - val_loss: 1363461059.4909 - val_mae: 23919.8809\n",
      "Epoch 292/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1063841100.8000 - mae: 21194.5586 - val_loss: 1415324548.6545 - val_mae: 24684.5059\n",
      "Epoch 293/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 1084646252.2182 - mae: 21482.1211 - val_loss: 1362313737.3091 - val_mae: 23834.3652\n",
      "Epoch 294/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1181619234.9091 - mae: 23160.6719 - val_loss: 1552498087.5636 - val_mae: 27245.3809\n",
      "Epoch 295/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1189501450.4727 - mae: 23366.0527 - val_loss: 1342200271.1273 - val_mae: 23832.8418\n",
      "Epoch 296/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 1103061586.6182 - mae: 22270.5469 - val_loss: 1491426350.5455 - val_mae: 25833.9023\n",
      "Epoch 297/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 1078314322.6182 - mae: 21554.8984 - val_loss: 1386015034.1818 - val_mae: 24292.7871\n",
      "Epoch 298/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 1081579417.6000 - mae: 21856.7559 - val_loss: 1344119549.6727 - val_mae: 24065.1445\n",
      "Epoch 299/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1124651307.0545 - mae: 21944.9160 - val_loss: 1451671875.4909 - val_mae: 25829.9160\n",
      "Epoch 300/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 1110349423.7091 - mae: 22482.2969 - val_loss: 1409048748.2182 - val_mae: 24580.3906\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 69us/step - loss: 1013254722.3273 - mae: 20764.5332 - val_loss: 1326777737.3091 - val_mae: 23472.2734\n",
      "Epoch 302/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1020475198.8364 - mae: 20629.4668 - val_loss: 1336545943.2727 - val_mae: 23603.9766\n",
      "Epoch 303/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1020662046.2545 - mae: 20788.5410 - val_loss: 1328683550.2545 - val_mae: 23444.8770\n",
      "Epoch 304/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1014956559.1273 - mae: 20733.8301 - val_loss: 1329983541.5273 - val_mae: 23514.1895\n",
      "Epoch 305/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 1042019322.1818 - mae: 20853.8906 - val_loss: 1320191974.4000 - val_mae: 23433.3906\n",
      "Epoch 306/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 1050529705.8909 - mae: 21217.7324 - val_loss: 1342504904.1455 - val_mae: 23613.7402\n",
      "Epoch 307/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1065131628.2182 - mae: 21408.3379 - val_loss: 1431397145.6000 - val_mae: 24992.4551\n",
      "Epoch 308/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1010899556.0727 - mae: 20837.3242 - val_loss: 1346055966.2545 - val_mae: 23605.4043\n",
      "Epoch 309/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1012440852.9455 - mae: 20708.8477 - val_loss: 1322805659.9273 - val_mae: 23398.8496\n",
      "Epoch 310/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 992409465.0182 - mae: 20324.2402 - val_loss: 1326337661.6727 - val_mae: 23422.9004\n",
      "Epoch 311/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 999493782.1091 - mae: 20480.7246 - val_loss: 1444197445.8182 - val_mae: 25130.3477\n",
      "Epoch 312/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1110033346.3273 - mae: 21919.0000 - val_loss: 1401800797.0909 - val_mae: 24574.1387\n",
      "Epoch 313/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 1043828770.9091 - mae: 21561.2617 - val_loss: 1426079290.1818 - val_mae: 24984.8867\n",
      "Epoch 314/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 982211820.2182 - mae: 20908.5781 - val_loss: 1340049603.4909 - val_mae: 23710.9961\n",
      "Epoch 315/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1039130219.6364 - mae: 21044.5195 - val_loss: 1350114003.7818 - val_mae: 24099.0234\n",
      "Epoch 316/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1140368707.4909 - mae: 23520.8613 - val_loss: 1318488557.3818 - val_mae: 23267.9551\n",
      "Epoch 317/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 1054070011.3455 - mae: 21090.4004 - val_loss: 1309219060.3636 - val_mae: 23275.1660\n",
      "Epoch 318/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 1041729054.2545 - mae: 21365.1484 - val_loss: 1588380166.9818 - val_mae: 27197.2188\n",
      "Epoch 319/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1064288128.0000 - mae: 21445.7695 - val_loss: 1317396670.8364 - val_mae: 23376.1309\n",
      "Epoch 320/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 978576631.8545 - mae: 20410.3027 - val_loss: 1335765971.7818 - val_mae: 23517.5879\n",
      "Epoch 321/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 970951673.0182 - mae: 20280.6289 - val_loss: 1326309990.4000 - val_mae: 23356.7637\n",
      "Epoch 322/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 988505506.9091 - mae: 20416.7129 - val_loss: 1307895198.2545 - val_mae: 23192.5801\n",
      "Epoch 323/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 996077824.0000 - mae: 20582.6484 - val_loss: 1330046989.9636 - val_mae: 23454.9902\n",
      "Epoch 324/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 985845324.8000 - mae: 20424.0742 - val_loss: 1361343718.4000 - val_mae: 23762.0273\n",
      "Epoch 325/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 963436219.3455 - mae: 20124.0586 - val_loss: 1333457342.8364 - val_mae: 23481.7461\n",
      "Epoch 326/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 971930778.7636 - mae: 20455.6934 - val_loss: 1311699763.2000 - val_mae: 23164.3164\n",
      "Epoch 327/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 991633993.3091 - mae: 20807.4766 - val_loss: 1445113160.1455 - val_mae: 25106.8945\n",
      "Epoch 328/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 966417419.6364 - mae: 20242.8555 - val_loss: 1283688559.7091 - val_mae: 23054.9941\n",
      "Epoch 329/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 968092193.7455 - mae: 20329.0469 - val_loss: 1309955928.4364 - val_mae: 23049.3047\n",
      "Epoch 330/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 956174856.1455 - mae: 20694.6934 - val_loss: 1457237497.0182 - val_mae: 25407.5840\n",
      "Epoch 331/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 970958444.2182 - mae: 20741.3379 - val_loss: 1297775685.8182 - val_mae: 23056.7480\n",
      "Epoch 332/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 942389536.5818 - mae: 20045.5645 - val_loss: 1293178763.6364 - val_mae: 22922.1777\n",
      "Epoch 333/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 938393864.1455 - mae: 20379.0469 - val_loss: 1320188511.4182 - val_mae: 23351.1680\n",
      "Epoch 334/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 991679198.2545 - mae: 20711.3652 - val_loss: 1276325843.7818 - val_mae: 22764.1816\n",
      "Epoch 335/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 967129319.5636 - mae: 20834.5801 - val_loss: 1295528443.3455 - val_mae: 22988.6367\n",
      "Epoch 336/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 983111773.0909 - mae: 20517.3848 - val_loss: 1278567942.9818 - val_mae: 22711.7754\n",
      "Epoch 337/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 957692610.3273 - mae: 20397.2910 - val_loss: 1312236157.6727 - val_mae: 23161.6973\n",
      "Epoch 338/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 934809846.6909 - mae: 20122.9219 - val_loss: 1396457339.3455 - val_mae: 24629.5098\n",
      "Epoch 339/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 956860608.0000 - mae: 20803.6719 - val_loss: 1390964084.3636 - val_mae: 24460.0957\n",
      "Epoch 340/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 977928001.7455 - mae: 20855.3516 - val_loss: 1315047593.8909 - val_mae: 23344.0879\n",
      "Epoch 341/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 912556886.1091 - mae: 20301.7363 - val_loss: 1275693700.6545 - val_mae: 22650.9766\n",
      "Epoch 342/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 955640693.5273 - mae: 21134.1523 - val_loss: 1425597314.3273 - val_mae: 25546.1289\n",
      "Epoch 343/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 1005085982.2545 - mae: 21143.8145 - val_loss: 1267760712.1455 - val_mae: 22500.3320\n",
      "Epoch 344/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 936103355.3455 - mae: 20139.5039 - val_loss: 1257947056.8727 - val_mae: 22362.1934\n",
      "Epoch 345/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 908545161.3091 - mae: 20091.4258 - val_loss: 1285448005.8182 - val_mae: 22776.4082\n",
      "Epoch 346/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 946628134.4000 - mae: 20443.5879 - val_loss: 1277668431.1273 - val_mae: 22780.7676\n",
      "Epoch 347/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 949077378.3273 - mae: 20612.7695 - val_loss: 1380732681.3091 - val_mae: 24327.9141\n",
      "Epoch 348/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 945293142.1091 - mae: 20266.9688 - val_loss: 1253287556.6545 - val_mae: 22537.0273\n",
      "Epoch 349/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 870095560.1455 - mae: 19538.4570 - val_loss: 1264251485.0909 - val_mae: 22475.0312\n",
      "Epoch 350/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 879581177.0182 - mae: 19808.0996 - val_loss: 1303214470.9818 - val_mae: 23244.4727\n",
      "Epoch 351/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 907255135.4182 - mae: 20274.6836 - val_loss: 1400122649.6000 - val_mae: 24774.2188\n",
      "Epoch 352/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 902109786.7636 - mae: 20275.5371 - val_loss: 1247686265.0182 - val_mae: 22312.8730\n",
      "Epoch 353/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 859686526.8364 - mae: 19528.5820 - val_loss: 1262488606.2545 - val_mae: 22540.4980\n",
      "Epoch 354/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 871748442.7636 - mae: 19782.5508 - val_loss: 1244063690.4727 - val_mae: 22188.8223\n",
      "Epoch 355/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 856462195.2000 - mae: 19656.8438 - val_loss: 1326530280.7273 - val_mae: 23644.7949\n",
      "Epoch 356/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 906309734.4000 - mae: 20096.5938 - val_loss: 1257420052.9455 - val_mae: 22704.5977\n",
      "Epoch 357/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 923460786.0364 - mae: 20580.4746 - val_loss: 1437324025.0182 - val_mae: 25551.9453\n",
      "Epoch 358/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 890694060.2182 - mae: 20651.1504 - val_loss: 1465808921.6000 - val_mae: 25630.7051\n",
      "Epoch 359/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 1061798409.3091 - mae: 23198.3809 - val_loss: 1255379635.2000 - val_mae: 22617.3145\n",
      "Epoch 360/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 968116120.4364 - mae: 21058.1992 - val_loss: 1223710089.3091 - val_mae: 22248.0547\n",
      "Epoch 361/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 859448969.3091 - mae: 19615.5020 - val_loss: 1250376510.8364 - val_mae: 22507.8184\n",
      "Epoch 362/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 878370464.5818 - mae: 20240.0527 - val_loss: 1238571948.2182 - val_mae: 22751.6953\n",
      "Epoch 363/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 868298166.6909 - mae: 19635.5176 - val_loss: 1231762580.9455 - val_mae: 22137.7480\n",
      "Epoch 364/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 858682992.8727 - mae: 19502.7500 - val_loss: 1218650226.0364 - val_mae: 21954.0508\n",
      "Epoch 365/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 838442030.5455 - mae: 19518.9414 - val_loss: 1225469477.2364 - val_mae: 22092.0332\n",
      "Epoch 366/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 858757984.5818 - mae: 19657.8594 - val_loss: 1269712295.5636 - val_mae: 22810.3926\n",
      "Epoch 367/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 877458441.3091 - mae: 19861.8438 - val_loss: 1584553001.8909 - val_mae: 27928.4863\n",
      "Epoch 368/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 977266987.0545 - mae: 21848.4805 - val_loss: 1550016716.8000 - val_mae: 27163.2461\n",
      "Epoch 369/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 910125370.1818 - mae: 21222.7910 - val_loss: 1316090733.3818 - val_mae: 23672.9180\n",
      "Epoch 370/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 869290949.8182 - mae: 20058.8438 - val_loss: 1490473246.2545 - val_mae: 26651.0371\n",
      "Epoch 371/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 996991899.9273 - mae: 21754.6836 - val_loss: 1481093022.2545 - val_mae: 26187.6348\n",
      "Epoch 372/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 873415353.0182 - mae: 19999.3574 - val_loss: 1406410251.6364 - val_mae: 25101.5234\n",
      "Epoch 373/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 912795102.2545 - mae: 20601.0605 - val_loss: 1524383990.6909 - val_mae: 26917.6113\n",
      "Epoch 374/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 854263154.0364 - mae: 20264.3809 - val_loss: 1223746334.2545 - val_mae: 22209.4727\n",
      "Epoch 375/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 855038297.6000 - mae: 19950.1230 - val_loss: 1240182239.4182 - val_mae: 22016.4414\n",
      "Epoch 376/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 859089529.0182 - mae: 19615.8008 - val_loss: 1262624823.8545 - val_mae: 22811.9824\n",
      "Epoch 377/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 885700745.3091 - mae: 20249.2090 - val_loss: 1282785768.7273 - val_mae: 23059.5781\n",
      "Epoch 378/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 915652499.2000 - mae: 20721.8301 - val_loss: 1326474656.5818 - val_mae: 23603.3086\n",
      "Epoch 379/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 896872506.1818 - mae: 21391.6934 - val_loss: 1181633114.7636 - val_mae: 21624.5234\n",
      "Epoch 380/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 878372695.2727 - mae: 20128.0117 - val_loss: 1251900672.0000 - val_mae: 22483.4180\n",
      "Epoch 381/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 919997988.0727 - mae: 21381.3184 - val_loss: 1205365385.3091 - val_mae: 21962.1309\n",
      "Epoch 382/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 908478675.7818 - mae: 20768.8477 - val_loss: 1209694038.1091 - val_mae: 21937.4414\n",
      "Epoch 383/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 805952551.5636 - mae: 19419.5312 - val_loss: 1212538891.6364 - val_mae: 21970.4492\n",
      "Epoch 384/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 792314761.3091 - mae: 19059.7344 - val_loss: 1195192701.6727 - val_mae: 21732.9863\n",
      "Epoch 385/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 758581427.2000 - mae: 18530.9980 - val_loss: 1186704349.0909 - val_mae: 21698.7891\n",
      "Epoch 386/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 770404655.7091 - mae: 19065.5703 - val_loss: 1200880409.6000 - val_mae: 21695.0586\n",
      "Epoch 387/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 787074214.4000 - mae: 19080.7461 - val_loss: 1222729530.1818 - val_mae: 22779.5566\n",
      "Epoch 388/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 836868125.0909 - mae: 19862.9883 - val_loss: 1216305677.9636 - val_mae: 22174.9688\n",
      "Epoch 389/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 804696037.2364 - mae: 19284.7109 - val_loss: 1162582272.0000 - val_mae: 21282.2910\n",
      "Epoch 390/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 755080621.3818 - mae: 18984.5996 - val_loss: 1188175590.4000 - val_mae: 22040.1133\n",
      "Epoch 391/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 770413099.0545 - mae: 19347.5469 - val_loss: 1168243148.8000 - val_mae: 21543.6348\n",
      "Epoch 392/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 732255032.4364 - mae: 18362.7559 - val_loss: 1173678761.8909 - val_mae: 21470.2188\n",
      "Epoch 393/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 736421896.1455 - mae: 18767.8848 - val_loss: 1138930099.2000 - val_mae: 21335.3867\n",
      "Epoch 394/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 764834054.9818 - mae: 19096.9590 - val_loss: 1173929630.2545 - val_mae: 21357.0410\n",
      "Epoch 395/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 770043324.5091 - mae: 19105.0059 - val_loss: 1152982765.3818 - val_mae: 21143.3945\n",
      "Epoch 396/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 762263259.9273 - mae: 18990.7402 - val_loss: 1153176431.7091 - val_mae: 21398.2266\n",
      "Epoch 397/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 740966524.5091 - mae: 18370.8223 - val_loss: 1278544453.8182 - val_mae: 23276.9531\n",
      "Epoch 398/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 709220619.6364 - mae: 18371.7656 - val_loss: 1117061294.5455 - val_mae: 21093.9043\n",
      "Epoch 399/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 709753206.6909 - mae: 18584.4219 - val_loss: 1137116793.0182 - val_mae: 21125.3438\n",
      "Epoch 400/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 749132044.8000 - mae: 19140.7031 - val_loss: 1146926440.7273 - val_mae: 21450.2773\n",
      "Epoch 401/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 795158334.2545 - mae: 19141.3281 - val_loss: 1164349211.9273 - val_mae: 21456.4902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 705641793.1636 - mae: 18324.6191 - val_loss: 1111079233.1636 - val_mae: 21042.2266\n",
      "Epoch 403/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 773259191.8545 - mae: 19416.4688 - val_loss: 1157693849.6000 - val_mae: 21309.7266\n",
      "Epoch 404/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 749532737.1636 - mae: 19402.2793 - val_loss: 1091848527.1273 - val_mae: 20872.8457\n",
      "Epoch 405/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 699275375.7091 - mae: 18265.3926 - val_loss: 1153984535.2727 - val_mae: 21546.6113\n",
      "Epoch 406/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 696103768.4364 - mae: 18003.8379 - val_loss: 1263722633.3091 - val_mae: 23564.0684\n",
      "Epoch 407/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 704682234.1818 - mae: 18522.5781 - val_loss: 1161045929.8909 - val_mae: 21843.3633\n",
      "Epoch 408/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 700721118.2545 - mae: 18515.3691 - val_loss: 1147949044.3636 - val_mae: 21668.6094\n",
      "Epoch 409/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 689950452.3636 - mae: 18361.5742 - val_loss: 1246823505.4545 - val_mae: 23628.0000\n",
      "Epoch 410/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 676726978.3273 - mae: 18177.9121 - val_loss: 1115031072.5818 - val_mae: 20882.3691\n",
      "Epoch 411/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 655657529.0182 - mae: 17592.6836 - val_loss: 1097802344.7273 - val_mae: 20785.2051\n",
      "Epoch 412/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 648342269.6727 - mae: 17792.2109 - val_loss: 1112753254.4000 - val_mae: 20915.8164\n",
      "Epoch 413/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 635706340.0727 - mae: 17593.1758 - val_loss: 1065731404.8000 - val_mae: 20393.1191\n",
      "Epoch 414/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 649388043.6364 - mae: 17899.0293 - val_loss: 1070726451.2000 - val_mae: 20331.2500\n",
      "Epoch 415/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 650300004.0727 - mae: 17759.1406 - val_loss: 1051378469.2364 - val_mae: 20268.0117\n",
      "Epoch 416/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 614828989.6727 - mae: 17260.3418 - val_loss: 1061544848.2909 - val_mae: 20211.4141\n",
      "Epoch 417/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 619729432.4364 - mae: 17364.7500 - val_loss: 1077031053.9636 - val_mae: 20523.3320\n",
      "Epoch 418/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 606238487.2727 - mae: 17282.8574 - val_loss: 1099241411.4909 - val_mae: 21195.6445\n",
      "Epoch 419/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 659465348.6545 - mae: 18129.4883 - val_loss: 1063564253.0909 - val_mae: 20405.3379\n",
      "Epoch 420/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 644710692.0727 - mae: 17885.8359 - val_loss: 1077370305.1636 - val_mae: 20627.9277\n",
      "Epoch 421/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 695643880.7273 - mae: 18698.3711 - val_loss: 1077587351.2727 - val_mae: 20884.6582\n",
      "Epoch 422/1000\n",
      "880/880 [==============================] - 0s 114us/step - loss: 629401409.1636 - mae: 17281.7207 - val_loss: 1100924727.8545 - val_mae: 21116.7324\n",
      "Epoch 423/1000\n",
      "880/880 [==============================] - 0s 101us/step - loss: 677137197.9636 - mae: 18514.4004 - val_loss: 1128061940.3636 - val_mae: 21729.2637\n",
      "Epoch 424/1000\n",
      "880/880 [==============================] - 0s 119us/step - loss: 694159804.5091 - mae: 18831.6680 - val_loss: 1044913405.6727 - val_mae: 20037.3906\n",
      "Epoch 425/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 655016993.7455 - mae: 18361.5098 - val_loss: 1192511178.4727 - val_mae: 23611.6758\n",
      "Epoch 426/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 690461645.9636 - mae: 18473.8555 - val_loss: 1078975867.3455 - val_mae: 20803.1816\n",
      "Epoch 427/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 664738981.8182 - mae: 18319.7773 - val_loss: 1184730968.4364 - val_mae: 21995.3086\n",
      "Epoch 428/1000\n",
      "880/880 [==============================] - 0s 85us/step - loss: 750686252.2182 - mae: 19804.7949 - val_loss: 1061691447.8545 - val_mae: 20782.6504\n",
      "Epoch 429/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 752210700.8000 - mae: 19548.9316 - val_loss: 1067168463.1273 - val_mae: 21077.9863\n",
      "Epoch 430/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 620241640.7273 - mae: 17541.4766 - val_loss: 1028479609.0182 - val_mae: 19858.0273\n",
      "Epoch 431/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 629949941.5273 - mae: 17730.7656 - val_loss: 1023473617.4545 - val_mae: 20061.8887\n",
      "Epoch 432/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 593973178.1818 - mae: 17199.1445 - val_loss: 1008141651.7818 - val_mae: 19710.9043\n",
      "Epoch 433/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 566605753.0182 - mae: 16646.2656 - val_loss: 998184501.5273 - val_mae: 19542.4473\n",
      "Epoch 434/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 559230845.0909 - mae: 16655.5781 - val_loss: 984429607.5636 - val_mae: 19501.1855\n",
      "Epoch 435/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 562692299.0545 - mae: 16765.4766 - val_loss: 1049349376.0000 - val_mae: 20020.6895\n",
      "Epoch 436/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 595803600.2909 - mae: 17254.6934 - val_loss: 987316226.3273 - val_mae: 19674.7520\n",
      "Epoch 437/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 633933011.2000 - mae: 17893.7383 - val_loss: 1108475992.4364 - val_mae: 21319.9141\n",
      "Epoch 438/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 639838881.7455 - mae: 18167.3477 - val_loss: 1128240325.8182 - val_mae: 21893.7090\n",
      "Epoch 439/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 645577931.6364 - mae: 18240.7227 - val_loss: 1256234237.6727 - val_mae: 25210.9043\n",
      "Epoch 440/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 728990223.1273 - mae: 19985.0430 - val_loss: 1048696620.2182 - val_mae: 21243.6191\n",
      "Epoch 441/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 607065944.4364 - mae: 17909.0527 - val_loss: 1012542303.4182 - val_mae: 20024.4004\n",
      "Epoch 442/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 567267140.6545 - mae: 16777.2734 - val_loss: 962678048.5818 - val_mae: 19441.8047\n",
      "Epoch 443/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 594019782.9818 - mae: 17139.8945 - val_loss: 1173955784.1455 - val_mae: 23633.1191\n",
      "Epoch 444/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 649672530.6182 - mae: 18126.2910 - val_loss: 945569179.9273 - val_mae: 19585.0586\n",
      "Epoch 445/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 654709594.7636 - mae: 18279.2090 - val_loss: 1236982458.1818 - val_mae: 22638.1504\n",
      "Epoch 446/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 718883493.2364 - mae: 19702.8574 - val_loss: 1009255193.6000 - val_mae: 20065.3281\n",
      "Epoch 447/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 634266141.6727 - mae: 17851.3809 - val_loss: 1138961184.5818 - val_mae: 22941.5391\n",
      "Epoch 448/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 545607350.1091 - mae: 16755.7754 - val_loss: 1071519178.4727 - val_mae: 21881.7559\n",
      "Epoch 449/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 567223699.7818 - mae: 16970.4590 - val_loss: 1003204824.4364 - val_mae: 20363.0137\n",
      "Epoch 450/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 537542992.2909 - mae: 16590.5645 - val_loss: 998212368.2909 - val_mae: 19848.2695\n",
      "Epoch 451/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 564774767.1273 - mae: 16911.0410 - val_loss: 987964346.1818 - val_mae: 19330.6836\n",
      "Epoch 452/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 517458684.5091 - mae: 16424.3711 - val_loss: 986902102.1091 - val_mae: 20047.5781\n",
      "Epoch 453/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 518241087.4182 - mae: 16099.4473 - val_loss: 1039370637.9636 - val_mae: 21290.0312\n",
      "Epoch 454/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 554416642.3273 - mae: 17003.5527 - val_loss: 945783069.0909 - val_mae: 19080.5723\n",
      "Epoch 455/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 533984417.7455 - mae: 16712.6094 - val_loss: 1189963080.1455 - val_mae: 22641.0312\n",
      "Epoch 456/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 664754939.9273 - mae: 18807.3125 - val_loss: 996177722.1818 - val_mae: 20151.5059\n",
      "Epoch 457/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 531993273.0182 - mae: 16716.4258 - val_loss: 1046095413.5273 - val_mae: 21193.9473\n",
      "Epoch 458/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 537089530.1818 - mae: 16473.5781 - val_loss: 946654239.4182 - val_mae: 19058.5410\n",
      "Epoch 459/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 490677057.7455 - mae: 15875.0908 - val_loss: 969548777.8909 - val_mae: 19337.1016\n",
      "Epoch 460/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 552127398.4000 - mae: 16781.7754 - val_loss: 1061976764.5091 - val_mae: 21691.4199\n",
      "Epoch 461/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 509221421.3818 - mae: 16281.3535 - val_loss: 928425281.1636 - val_mae: 19058.3164\n",
      "Epoch 462/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 541754860.2182 - mae: 16758.4980 - val_loss: 959024629.5273 - val_mae: 19168.4863\n",
      "Epoch 463/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 542057776.2909 - mae: 16907.0293 - val_loss: 1095215830.1091 - val_mae: 22752.7344\n",
      "Epoch 464/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 509579837.0909 - mae: 16562.1621 - val_loss: 942885529.6000 - val_mae: 18879.2168\n",
      "Epoch 465/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 468320313.0182 - mae: 15383.9512 - val_loss: 945469839.1273 - val_mae: 19183.7734\n",
      "Epoch 466/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 467799269.2364 - mae: 15532.2217 - val_loss: 922997336.4364 - val_mae: 19039.8672\n",
      "Epoch 467/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 469118919.5636 - mae: 15433.2373 - val_loss: 969980277.5273 - val_mae: 19343.0039\n",
      "Epoch 468/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 523382889.8909 - mae: 16390.9336 - val_loss: 953720616.7273 - val_mae: 19863.6016\n",
      "Epoch 469/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 656496833.1636 - mae: 17847.7383 - val_loss: 1038940732.5091 - val_mae: 20100.1133\n",
      "Epoch 470/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 610498980.0727 - mae: 17813.0859 - val_loss: 977518820.0727 - val_mae: 20737.4590\n",
      "Epoch 471/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 695286031.1273 - mae: 18823.1797 - val_loss: 1240094682.7636 - val_mae: 25521.2871\n",
      "Epoch 472/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 780896898.9091 - mae: 20412.9766 - val_loss: 1117274442.4727 - val_mae: 22166.0508\n",
      "Epoch 473/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 794077338.7636 - mae: 20739.7676 - val_loss: 1168509095.5636 - val_mae: 21448.4219\n",
      "Epoch 474/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 687779826.0364 - mae: 19340.9023 - val_loss: 919488918.1091 - val_mae: 19223.2539\n",
      "Epoch 475/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 495210507.6364 - mae: 15885.6475 - val_loss: 920811922.6182 - val_mae: 19016.9180\n",
      "Epoch 476/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 490414778.1818 - mae: 15719.5293 - val_loss: 956613204.9455 - val_mae: 19395.8770\n",
      "Epoch 477/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 466921095.5636 - mae: 15347.9307 - val_loss: 936448672.5818 - val_mae: 19190.5098\n",
      "Epoch 478/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 463233634.9091 - mae: 15493.3311 - val_loss: 936976522.4727 - val_mae: 18919.7461\n",
      "Epoch 479/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 459710938.1818 - mae: 15323.9844 - val_loss: 950091565.3818 - val_mae: 18951.9707\n",
      "Epoch 480/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 484995937.1636 - mae: 15939.2412 - val_loss: 937228797.6727 - val_mae: 18922.1738\n",
      "Epoch 481/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 487579752.1455 - mae: 15834.1309 - val_loss: 968763276.8000 - val_mae: 19967.0195\n",
      "Epoch 482/1000\n",
      "880/880 [==============================] - 0s 63us/step - loss: 453763894.1091 - mae: 15347.9043 - val_loss: 924467059.2000 - val_mae: 18852.7109\n",
      "Epoch 483/1000\n",
      "880/880 [==============================] - 0s 64us/step - loss: 448219080.1455 - mae: 15307.5996 - val_loss: 952004080.8727 - val_mae: 19762.4531\n",
      "Epoch 484/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 484436953.0182 - mae: 15951.2588 - val_loss: 938704416.5818 - val_mae: 19038.4434\n",
      "Epoch 485/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 485988834.9091 - mae: 16038.8770 - val_loss: 916164248.4364 - val_mae: 18688.5312\n",
      "Epoch 486/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 477293735.5636 - mae: 15538.4082 - val_loss: 978060446.2545 - val_mae: 19588.8691\n",
      "Epoch 487/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 553136052.3636 - mae: 17136.8633 - val_loss: 917727787.0545 - val_mae: 18997.2148\n",
      "Epoch 488/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 466743709.0909 - mae: 15501.2090 - val_loss: 1033467543.2727 - val_mae: 20447.1699\n",
      "Epoch 489/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 489246717.0909 - mae: 15564.6953 - val_loss: 901495752.1455 - val_mae: 18779.9805\n",
      "Epoch 490/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 489092375.2727 - mae: 15710.0771 - val_loss: 994550420.9455 - val_mae: 20768.6543\n",
      "Epoch 491/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 493929323.0545 - mae: 16164.2314 - val_loss: 904735322.7636 - val_mae: 18761.8516\n",
      "Epoch 492/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 423564326.9818 - mae: 14672.8662 - val_loss: 929659948.2182 - val_mae: 19454.4004\n",
      "Epoch 493/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 453193904.2909 - mae: 15666.4863 - val_loss: 927636948.9455 - val_mae: 19031.6191\n",
      "Epoch 494/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 420442395.9273 - mae: 14744.0146 - val_loss: 900128607.4182 - val_mae: 18631.6230\n",
      "Epoch 495/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 432267853.9636 - mae: 14842.4082 - val_loss: 949849766.4000 - val_mae: 19303.3145\n",
      "Epoch 496/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 423975702.1091 - mae: 14918.2988 - val_loss: 903883232.5818 - val_mae: 18670.2109\n",
      "Epoch 497/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 411009162.4727 - mae: 14593.8799 - val_loss: 936290792.7273 - val_mae: 18702.5488\n",
      "Epoch 498/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 434627404.8000 - mae: 15153.0771 - val_loss: 905114155.0545 - val_mae: 18715.8438\n",
      "Epoch 499/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 403880499.2000 - mae: 14681.0322 - val_loss: 933374054.4000 - val_mae: 19313.2734\n",
      "Epoch 500/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 412357140.9455 - mae: 14745.2930 - val_loss: 909864429.3818 - val_mae: 18588.1816\n",
      "Epoch 501/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 424128194.9091 - mae: 14884.0635 - val_loss: 910269647.1273 - val_mae: 18652.4707\n",
      "Epoch 502/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 407894160.8727 - mae: 14519.0225 - val_loss: 961157446.9818 - val_mae: 20234.1641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 420623512.4364 - mae: 15028.8809 - val_loss: 1024861989.2364 - val_mae: 20352.5234\n",
      "Epoch 504/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 455796004.6545 - mae: 15612.3594 - val_loss: 971329916.5091 - val_mae: 20056.4824\n",
      "Epoch 505/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 421751311.1273 - mae: 14730.1953 - val_loss: 903211341.9636 - val_mae: 18933.6289\n",
      "Epoch 506/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 428675954.6182 - mae: 15076.3545 - val_loss: 950586004.9455 - val_mae: 18944.2324\n",
      "Epoch 507/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 422972808.7273 - mae: 14937.9502 - val_loss: 907118841.0182 - val_mae: 18779.3203\n",
      "Epoch 508/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 445618115.4909 - mae: 15283.2842 - val_loss: 919820429.9636 - val_mae: 18730.5195\n",
      "Epoch 509/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 417890363.3455 - mae: 14908.9277 - val_loss: 943333444.6545 - val_mae: 19874.6309\n",
      "Epoch 510/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 434003780.0727 - mae: 15054.7090 - val_loss: 937801420.8000 - val_mae: 18766.4258\n",
      "Epoch 511/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 409242174.2545 - mae: 14564.6436 - val_loss: 926503353.0182 - val_mae: 18893.8418\n",
      "Epoch 512/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 483506075.9273 - mae: 16006.3379 - val_loss: 1040163970.3273 - val_mae: 22174.3281\n",
      "Epoch 513/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 516975312.8727 - mae: 16865.8164 - val_loss: 1002477500.5091 - val_mae: 20222.3652\n",
      "Epoch 514/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 587563779.4909 - mae: 17242.2090 - val_loss: 1322139117.3818 - val_mae: 27139.5020\n",
      "Epoch 515/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 537912138.4727 - mae: 16508.4746 - val_loss: 900870863.1273 - val_mae: 18762.1211\n",
      "Epoch 516/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 466939010.9091 - mae: 15128.6895 - val_loss: 946271732.3636 - val_mae: 18940.8438\n",
      "Epoch 517/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 426073440.5818 - mae: 15021.6348 - val_loss: 888122007.2727 - val_mae: 18567.4043\n",
      "Epoch 518/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 416690650.1818 - mae: 14627.8408 - val_loss: 912587352.4364 - val_mae: 18863.8652\n",
      "Epoch 519/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 414452569.6000 - mae: 14954.4209 - val_loss: 941387692.2182 - val_mae: 19243.5273\n",
      "Epoch 520/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 407568897.7455 - mae: 14519.6035 - val_loss: 905473314.9091 - val_mae: 18588.2617\n",
      "Epoch 521/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 381042527.4182 - mae: 14057.0137 - val_loss: 901016485.2364 - val_mae: 18507.8867\n",
      "Epoch 522/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 395361101.3818 - mae: 14434.6367 - val_loss: 895056872.7273 - val_mae: 18466.5781\n",
      "Epoch 523/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 399336109.3818 - mae: 14487.3242 - val_loss: 969813153.7455 - val_mae: 20147.1797\n",
      "Epoch 524/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 447527478.1091 - mae: 15559.9844 - val_loss: 982094118.4000 - val_mae: 19801.2051\n",
      "Epoch 525/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 421135319.8545 - mae: 14688.7783 - val_loss: 1082126419.7818 - val_mae: 22920.1992\n",
      "Epoch 526/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 430144843.6364 - mae: 15168.5908 - val_loss: 885648278.1091 - val_mae: 18515.4473\n",
      "Epoch 527/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 391915568.2909 - mae: 14372.4023 - val_loss: 923307024.2909 - val_mae: 18519.7070\n",
      "Epoch 528/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 407805584.2909 - mae: 14628.5996 - val_loss: 1070550139.3455 - val_mae: 22792.4258\n",
      "Epoch 529/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 436274374.9818 - mae: 15579.5098 - val_loss: 921570022.4000 - val_mae: 18788.5156\n",
      "Epoch 530/1000\n",
      "880/880 [==============================] - 0s 65us/step - loss: 395179556.0727 - mae: 14421.2285 - val_loss: 916214692.0727 - val_mae: 18671.9902\n",
      "Epoch 531/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 477571180.8000 - mae: 16036.8672 - val_loss: 1296414692.0727 - val_mae: 27377.0859\n",
      "Epoch 532/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 536546067.2000 - mae: 17250.8320 - val_loss: 908259513.0182 - val_mae: 18709.6445\n",
      "Epoch 533/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 483981978.7636 - mae: 16280.1055 - val_loss: 1008863706.7636 - val_mae: 19927.4629\n",
      "Epoch 534/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 501386866.6182 - mae: 16180.3555 - val_loss: 1041504281.6000 - val_mae: 22108.5273\n",
      "Epoch 535/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 485924888.4364 - mae: 16228.0479 - val_loss: 948226899.7818 - val_mae: 19052.6641\n",
      "Epoch 536/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 436577109.5273 - mae: 15219.3096 - val_loss: 946166275.4909 - val_mae: 18759.8965\n",
      "Epoch 537/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 466642100.3636 - mae: 15662.4912 - val_loss: 988203784.1455 - val_mae: 20909.2051\n",
      "Epoch 538/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 401201003.6364 - mae: 14561.5254 - val_loss: 924322957.9636 - val_mae: 18572.6113\n",
      "Epoch 539/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 386446557.6727 - mae: 14315.4775 - val_loss: 903236434.6182 - val_mae: 18520.4590\n",
      "Epoch 540/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 395098476.8000 - mae: 14560.1904 - val_loss: 1050650044.5091 - val_mae: 22578.8867\n",
      "Epoch 541/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 492993897.8909 - mae: 16566.4141 - val_loss: 969440004.6545 - val_mae: 20403.5957\n",
      "Epoch 542/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 568533784.4364 - mae: 17042.7266 - val_loss: 990534559.4182 - val_mae: 19797.0176\n",
      "Epoch 543/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 585155192.4364 - mae: 16943.9863 - val_loss: 958167446.1091 - val_mae: 20056.0195\n",
      "Epoch 544/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 457870177.1636 - mae: 15571.9316 - val_loss: 994395390.8364 - val_mae: 20928.7500\n",
      "Epoch 545/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 439335645.6727 - mae: 15391.7354 - val_loss: 914702668.8000 - val_mae: 18922.1113\n",
      "Epoch 546/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 402610194.0364 - mae: 14108.6650 - val_loss: 916036449.7455 - val_mae: 18574.7383\n",
      "Epoch 547/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 389854937.0182 - mae: 14182.2910 - val_loss: 925527498.4727 - val_mae: 19380.3633\n",
      "Epoch 548/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 361036784.2909 - mae: 13715.4932 - val_loss: 891942316.2182 - val_mae: 18520.9316\n",
      "Epoch 549/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 371210341.2364 - mae: 14179.5322 - val_loss: 932189837.9636 - val_mae: 18643.7363\n",
      "Epoch 550/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 421669197.9636 - mae: 15254.5342 - val_loss: 1050309185.1636 - val_mae: 22522.4609\n",
      "Epoch 551/1000\n",
      "880/880 [==============================] - 0s 89us/step - loss: 445034028.8000 - mae: 15722.7178 - val_loss: 939685395.7818 - val_mae: 19934.8223\n",
      "Epoch 552/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 444265608.1455 - mae: 15291.3389 - val_loss: 1064487698.6182 - val_mae: 20414.0000\n",
      "Epoch 553/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 417903472.8727 - mae: 15038.8047 - val_loss: 899187840.0000 - val_mae: 18449.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 389616913.4545 - mae: 14144.0410 - val_loss: 1053019389.6727 - val_mae: 22543.0156\n",
      "Epoch 555/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 412453353.3091 - mae: 14831.4570 - val_loss: 915875272.1455 - val_mae: 18506.0117\n",
      "Epoch 556/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 362535422.8364 - mae: 13837.8057 - val_loss: 926449805.9636 - val_mae: 19085.3223\n",
      "Epoch 557/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 409282223.1273 - mae: 14855.4287 - val_loss: 1010365878.6909 - val_mae: 21270.9355\n",
      "Epoch 558/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 371124008.7273 - mae: 13930.1855 - val_loss: 904036936.1455 - val_mae: 18580.1875\n",
      "Epoch 559/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 348552697.0182 - mae: 13427.1680 - val_loss: 906427074.3273 - val_mae: 18673.5684\n",
      "Epoch 560/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 347972069.2364 - mae: 13544.7217 - val_loss: 890916199.5636 - val_mae: 18655.9551\n",
      "Epoch 561/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 356418269.6727 - mae: 13715.3838 - val_loss: 961549952.0000 - val_mae: 20396.6445\n",
      "Epoch 562/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 436182284.8000 - mae: 15345.6230 - val_loss: 965400008.1455 - val_mae: 19316.6699\n",
      "Epoch 563/1000\n",
      "880/880 [==============================] - 0s 66us/step - loss: 374615570.6182 - mae: 14284.9717 - val_loss: 906731745.7455 - val_mae: 18977.5234\n",
      "Epoch 564/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 351244566.9818 - mae: 13616.5303 - val_loss: 897973571.4909 - val_mae: 18498.1094\n",
      "Epoch 565/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 340394226.6182 - mae: 13486.9141 - val_loss: 910739187.2000 - val_mae: 18951.9316\n",
      "Epoch 566/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 343283332.0727 - mae: 13550.4736 - val_loss: 917900196.0727 - val_mae: 19077.8457\n",
      "Epoch 567/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 351379698.6182 - mae: 13687.5645 - val_loss: 899660448.5818 - val_mae: 18621.4980\n",
      "Epoch 568/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 328363802.7636 - mae: 13073.3477 - val_loss: 899895854.5455 - val_mae: 18567.1172\n",
      "Epoch 569/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 329214310.6909 - mae: 13118.9287 - val_loss: 906360322.3273 - val_mae: 18633.1387\n",
      "Epoch 570/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 368244065.1636 - mae: 14074.8848 - val_loss: 937576927.4182 - val_mae: 19704.1367\n",
      "Epoch 571/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 349129537.1636 - mae: 13429.8047 - val_loss: 905774446.5455 - val_mae: 18718.2324\n",
      "Epoch 572/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 389666645.5273 - mae: 14580.3008 - val_loss: 907318749.0909 - val_mae: 19208.6309\n",
      "Epoch 573/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 383198802.9091 - mae: 14344.6387 - val_loss: 914031256.4364 - val_mae: 18821.0547\n",
      "Epoch 574/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 368091234.3273 - mae: 13885.2227 - val_loss: 1052768833.1636 - val_mae: 22693.5918\n",
      "Epoch 575/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 416444798.8364 - mae: 14996.8760 - val_loss: 924094761.8909 - val_mae: 19026.5957\n",
      "Epoch 576/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 366159598.5455 - mae: 13992.3799 - val_loss: 888650130.6182 - val_mae: 18610.3438\n",
      "Epoch 577/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 369569705.3091 - mae: 13929.1172 - val_loss: 882292462.5455 - val_mae: 18570.3906\n",
      "Epoch 578/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 338076196.0727 - mae: 13144.8877 - val_loss: 922513730.3273 - val_mae: 19146.8359\n",
      "Epoch 579/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 343240969.8909 - mae: 13621.6309 - val_loss: 944980603.3455 - val_mae: 20293.8223\n",
      "Epoch 580/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 375608235.6364 - mae: 13964.2021 - val_loss: 1103155365.2364 - val_mae: 20965.4668\n",
      "Epoch 581/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 432704041.3091 - mae: 15238.3184 - val_loss: 936819066.1818 - val_mae: 19982.3867\n",
      "Epoch 582/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 395614127.7091 - mae: 14622.0527 - val_loss: 905108232.1455 - val_mae: 18836.2461\n",
      "Epoch 583/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 376541650.6182 - mae: 14265.9912 - val_loss: 893457939.7818 - val_mae: 18709.7051\n",
      "Epoch 584/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 363328080.2909 - mae: 13902.5215 - val_loss: 868174206.8364 - val_mae: 18556.6719\n",
      "Epoch 585/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 379731340.8000 - mae: 14307.1279 - val_loss: 902687251.7818 - val_mae: 19092.3633\n",
      "Epoch 586/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 358863922.0364 - mae: 13816.0850 - val_loss: 899351897.6000 - val_mae: 19096.4941\n",
      "Epoch 587/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 329812831.4182 - mae: 13322.0547 - val_loss: 906650864.8727 - val_mae: 18657.0371\n",
      "Epoch 588/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 363281552.2909 - mae: 13965.0742 - val_loss: 893094073.0182 - val_mae: 18905.1797\n",
      "Epoch 589/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 383563636.3636 - mae: 14293.1650 - val_loss: 1021071165.6727 - val_mae: 22171.4824\n",
      "Epoch 590/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 462390892.2182 - mae: 16209.5049 - val_loss: 954908405.5273 - val_mae: 19289.8242\n",
      "Epoch 591/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 356629867.6364 - mae: 13681.4229 - val_loss: 913100676.6545 - val_mae: 19263.1523\n",
      "Epoch 592/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 349617371.9273 - mae: 13755.9463 - val_loss: 923334959.7091 - val_mae: 19333.5684\n",
      "Epoch 593/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 319855022.8364 - mae: 13020.5137 - val_loss: 888146443.6364 - val_mae: 18517.0254\n",
      "Epoch 594/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 311466197.5273 - mae: 12807.7012 - val_loss: 889415190.1091 - val_mae: 18591.5703\n",
      "Epoch 595/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 314833962.4727 - mae: 12864.9727 - val_loss: 880230221.9636 - val_mae: 18562.2012\n",
      "Epoch 596/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 323760311.2727 - mae: 13221.4375 - val_loss: 893147728.2909 - val_mae: 18513.9941\n",
      "Epoch 597/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 341449256.7273 - mae: 13538.9170 - val_loss: 902494605.9636 - val_mae: 19315.8418\n",
      "Epoch 598/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 365434829.3818 - mae: 14103.7412 - val_loss: 894210615.8545 - val_mae: 18551.8477\n",
      "Epoch 599/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 336178693.2364 - mae: 13337.4561 - val_loss: 913008243.2000 - val_mae: 19192.3906\n",
      "Epoch 600/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 321426450.6182 - mae: 13038.7480 - val_loss: 883760530.6182 - val_mae: 18525.7617\n",
      "Epoch 601/1000\n",
      "880/880 [==============================] - 0s 92us/step - loss: 306212192.8727 - mae: 12755.3828 - val_loss: 923338349.3818 - val_mae: 19830.9727\n",
      "Epoch 602/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 318479344.8727 - mae: 12956.1572 - val_loss: 901123345.4545 - val_mae: 18639.7227\n",
      "Epoch 603/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 349254804.3636 - mae: 13718.2998 - val_loss: 893854615.2727 - val_mae: 18922.1816\n",
      "Epoch 604/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 337660742.9818 - mae: 13473.5928 - val_loss: 889833094.9818 - val_mae: 18799.4297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 297084118.6909 - mae: 12493.8047 - val_loss: 889719422.8364 - val_mae: 18896.0020\n",
      "Epoch 606/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 300513255.2727 - mae: 12484.3115 - val_loss: 919257527.8545 - val_mae: 20046.7871\n",
      "Epoch 607/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 318133494.1091 - mae: 12908.4102 - val_loss: 892757270.1091 - val_mae: 18551.6660\n",
      "Epoch 608/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 310163282.0364 - mae: 12739.6367 - val_loss: 933495744.0000 - val_mae: 20179.0098\n",
      "Epoch 609/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 311416093.6727 - mae: 12872.0010 - val_loss: 910549952.0000 - val_mae: 19711.3223\n",
      "Epoch 610/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 315637842.6182 - mae: 12954.6260 - val_loss: 891352094.2545 - val_mae: 18878.4531\n",
      "Epoch 611/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 307931056.8727 - mae: 12883.0830 - val_loss: 971257398.6909 - val_mae: 19483.4121\n",
      "Epoch 612/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 390176175.7091 - mae: 14774.4863 - val_loss: 1122616271.1273 - val_mae: 24163.4004\n",
      "Epoch 613/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 349039921.4545 - mae: 14043.5117 - val_loss: 923629081.6000 - val_mae: 19458.8223\n",
      "Epoch 614/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 307247788.5091 - mae: 12756.5469 - val_loss: 882685584.2909 - val_mae: 18577.3906\n",
      "Epoch 615/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 293443333.8182 - mae: 12399.7295 - val_loss: 878487844.0727 - val_mae: 18922.9824\n",
      "Epoch 616/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 312911532.2182 - mae: 12920.1475 - val_loss: 893248313.0182 - val_mae: 18866.9883\n",
      "Epoch 617/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 403894366.2545 - mae: 14835.2559 - val_loss: 890265142.6909 - val_mae: 18586.1152\n",
      "Epoch 618/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 472900809.8909 - mae: 15882.5098 - val_loss: 953647241.3091 - val_mae: 20472.4219\n",
      "Epoch 619/1000\n",
      "880/880 [==============================] - 0s 67us/step - loss: 347945573.8182 - mae: 13451.3682 - val_loss: 1019254147.4909 - val_mae: 20166.4980\n",
      "Epoch 620/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 420360629.8182 - mae: 15142.9160 - val_loss: 1032364403.2000 - val_mae: 22576.5371\n",
      "Epoch 621/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 400119745.1636 - mae: 14732.7666 - val_loss: 921291418.7636 - val_mae: 19984.8145\n",
      "Epoch 622/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 374114882.9091 - mae: 14076.2100 - val_loss: 985202356.3636 - val_mae: 19834.3945\n",
      "Epoch 623/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 364869338.1818 - mae: 14343.1025 - val_loss: 916522971.9273 - val_mae: 19650.4355\n",
      "Epoch 624/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 324189176.4364 - mae: 13249.4453 - val_loss: 898815767.2727 - val_mae: 18725.1289\n",
      "Epoch 625/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 311177927.5636 - mae: 12766.3027 - val_loss: 903497904.8727 - val_mae: 18743.1250\n",
      "Epoch 626/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 303344886.6909 - mae: 12704.9014 - val_loss: 949903994.1818 - val_mae: 20702.4004\n",
      "Epoch 627/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 302100987.6364 - mae: 12733.0000 - val_loss: 873674502.9818 - val_mae: 18562.6211\n",
      "Epoch 628/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 311142155.0545 - mae: 12964.7871 - val_loss: 894877068.8000 - val_mae: 18600.3535\n",
      "Epoch 629/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 308760942.5455 - mae: 12913.9844 - val_loss: 925619993.6000 - val_mae: 19973.9902\n",
      "Epoch 630/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 301967206.6909 - mae: 12705.5049 - val_loss: 911873347.4909 - val_mae: 18831.7500\n",
      "Epoch 631/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 320681215.1273 - mae: 13264.0840 - val_loss: 950504900.6545 - val_mae: 20677.8320\n",
      "Epoch 632/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 317359152.2909 - mae: 13102.4980 - val_loss: 892167845.2364 - val_mae: 18810.8516\n",
      "Epoch 633/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 286964534.1091 - mae: 12347.2197 - val_loss: 936880690.0364 - val_mae: 20232.7031\n",
      "Epoch 634/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 301219081.6000 - mae: 12760.2168 - val_loss: 872687427.4909 - val_mae: 18553.4668\n",
      "Epoch 635/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 314157338.1818 - mae: 12927.3555 - val_loss: 899218236.5091 - val_mae: 19049.2871\n",
      "Epoch 636/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 294558299.9273 - mae: 12558.5137 - val_loss: 880338024.7273 - val_mae: 18865.1230\n",
      "Epoch 637/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 282590297.6000 - mae: 12182.7451 - val_loss: 894845143.2727 - val_mae: 18568.7402\n",
      "Epoch 638/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 292443673.6000 - mae: 12418.5283 - val_loss: 907951896.4364 - val_mae: 19869.1055\n",
      "Epoch 639/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 383919905.1636 - mae: 14602.3096 - val_loss: 929937702.4000 - val_mae: 19323.1406\n",
      "Epoch 640/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 478114279.5636 - mae: 16381.6064 - val_loss: 916603558.4000 - val_mae: 18681.8906\n",
      "Epoch 641/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 370172461.9636 - mae: 14250.9658 - val_loss: 1022263643.9273 - val_mae: 22131.9473\n",
      "Epoch 642/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 395044907.6364 - mae: 14587.0615 - val_loss: 1067350936.4364 - val_mae: 20769.2090\n",
      "Epoch 643/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 411934653.3818 - mae: 15123.7979 - val_loss: 1077516073.8909 - val_mae: 23000.0723\n",
      "Epoch 644/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 365583240.7273 - mae: 14015.6094 - val_loss: 895720201.3091 - val_mae: 18409.2754\n",
      "Epoch 645/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 302598299.3455 - mae: 12529.6963 - val_loss: 877153218.3273 - val_mae: 18478.5664\n",
      "Epoch 646/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 297092274.3273 - mae: 12383.3350 - val_loss: 865353139.2000 - val_mae: 18492.6191\n",
      "Epoch 647/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 300527409.1636 - mae: 12715.0654 - val_loss: 885093087.4182 - val_mae: 18447.6230\n",
      "Epoch 648/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 305032735.7091 - mae: 12738.1240 - val_loss: 975429554.0364 - val_mae: 20990.3574\n",
      "Epoch 649/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 299599411.7818 - mae: 12815.8447 - val_loss: 907406917.8182 - val_mae: 18716.8906\n",
      "Epoch 650/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 292937515.6364 - mae: 12352.7432 - val_loss: 891457869.9636 - val_mae: 19110.6133\n",
      "Epoch 651/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 273320339.2000 - mae: 12110.4395 - val_loss: 879313162.4727 - val_mae: 18478.7656\n",
      "Epoch 652/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 290903904.0000 - mae: 12461.6367 - val_loss: 919198146.3273 - val_mae: 20193.4473\n",
      "Epoch 653/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 310986616.4364 - mae: 13020.0645 - val_loss: 885647887.1273 - val_mae: 18665.1055\n",
      "Epoch 654/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 305576525.3818 - mae: 12764.8652 - val_loss: 905227243.0545 - val_mae: 18910.5723\n",
      "Epoch 655/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 285022050.3273 - mae: 12342.7061 - val_loss: 964007685.8182 - val_mae: 20657.7949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 292630484.3636 - mae: 12555.4629 - val_loss: 874756429.9636 - val_mae: 18516.3066\n",
      "Epoch 657/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 287368415.4182 - mae: 12351.5781 - val_loss: 910462313.8909 - val_mae: 19382.5820\n",
      "Epoch 658/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 274339221.5273 - mae: 11948.0684 - val_loss: 893941935.7091 - val_mae: 19294.5137\n",
      "Epoch 659/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 273699410.0364 - mae: 12036.1826 - val_loss: 887967519.4182 - val_mae: 19122.4902\n",
      "Epoch 660/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 268824936.7273 - mae: 11906.5527 - val_loss: 893966521.0182 - val_mae: 19055.2910\n",
      "Epoch 661/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 259402291.7818 - mae: 11791.8066 - val_loss: 885459805.0909 - val_mae: 19032.9414\n",
      "Epoch 662/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 256832683.6364 - mae: 11659.8975 - val_loss: 887631050.4727 - val_mae: 18615.6211\n",
      "Epoch 663/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 279700770.9091 - mae: 12270.6748 - val_loss: 911060534.6909 - val_mae: 19693.8418\n",
      "Epoch 664/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 342015597.9636 - mae: 13843.5459 - val_loss: 914039221.5273 - val_mae: 18792.0234\n",
      "Epoch 665/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 321405556.6545 - mae: 13080.7021 - val_loss: 996950475.6364 - val_mae: 21522.4570\n",
      "Epoch 666/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 380255851.0545 - mae: 14539.0576 - val_loss: 942798774.6909 - val_mae: 19252.4180\n",
      "Epoch 667/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 308902463.4182 - mae: 12680.3916 - val_loss: 920153292.8000 - val_mae: 19589.3496\n",
      "Epoch 668/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 298733933.9636 - mae: 12481.0195 - val_loss: 885946108.5091 - val_mae: 18747.9258\n",
      "Epoch 669/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 280161859.4909 - mae: 12241.3555 - val_loss: 911064390.9818 - val_mae: 19013.1289\n",
      "Epoch 670/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 283762003.7818 - mae: 12182.9834 - val_loss: 863854146.3273 - val_mae: 18471.5020\n",
      "Epoch 671/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 275320917.5273 - mae: 12196.9043 - val_loss: 916841800.1455 - val_mae: 19723.1641\n",
      "Epoch 672/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 279213125.2364 - mae: 12014.8447 - val_loss: 871464525.9636 - val_mae: 18521.8730\n",
      "Epoch 673/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 274223986.0364 - mae: 12082.0264 - val_loss: 898548891.9273 - val_mae: 18934.5645\n",
      "Epoch 674/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 273555492.6545 - mae: 12182.8906 - val_loss: 892922868.3636 - val_mae: 19348.0781\n",
      "Epoch 675/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 274748730.7636 - mae: 12172.8877 - val_loss: 884786085.2364 - val_mae: 18715.7871\n",
      "Epoch 676/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 248446011.0545 - mae: 11542.1533 - val_loss: 892633533.6727 - val_mae: 18754.1582\n",
      "Epoch 677/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 248386815.1273 - mae: 11434.4473 - val_loss: 894188868.6545 - val_mae: 19245.0273\n",
      "Epoch 678/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 263717510.6909 - mae: 11944.7832 - val_loss: 897376431.7091 - val_mae: 19493.1680\n",
      "Epoch 679/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 266105648.2909 - mae: 12102.1367 - val_loss: 893971545.6000 - val_mae: 19058.8789\n",
      "Epoch 680/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 278299816.4364 - mae: 12284.8291 - val_loss: 872906011.9273 - val_mae: 18932.1816\n",
      "Epoch 681/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 250497168.8727 - mae: 11483.9277 - val_loss: 898584124.5091 - val_mae: 19165.5742\n",
      "Epoch 682/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 256166881.1636 - mae: 11613.7275 - val_loss: 881277377.1636 - val_mae: 18690.6621\n",
      "Epoch 683/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 304426144.0000 - mae: 12788.6445 - val_loss: 893282540.2182 - val_mae: 19365.3574\n",
      "Epoch 684/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 282322698.4727 - mae: 12453.2217 - val_loss: 933227127.8545 - val_mae: 20380.5039\n",
      "Epoch 685/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 291257088.0000 - mae: 12531.9951 - val_loss: 885448039.5636 - val_mae: 18703.4590\n",
      "Epoch 686/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 280044336.0000 - mae: 12451.1299 - val_loss: 886042540.2182 - val_mae: 18681.1191\n",
      "Epoch 687/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 305912197.8182 - mae: 12686.7148 - val_loss: 914733117.6727 - val_mae: 19881.4160\n",
      "Epoch 688/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 292128007.5636 - mae: 12529.7705 - val_loss: 903750296.4364 - val_mae: 18935.6094\n",
      "Epoch 689/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 272791623.8545 - mae: 12340.2002 - val_loss: 904107880.7273 - val_mae: 19562.3613\n",
      "Epoch 690/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 264935300.6545 - mae: 11848.9023 - val_loss: 919580196.0727 - val_mae: 19742.8945\n",
      "Epoch 691/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 243245219.7818 - mae: 11584.0625 - val_loss: 886496635.3455 - val_mae: 18540.1523\n",
      "Epoch 692/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 251619132.2182 - mae: 11618.3467 - val_loss: 887747629.3818 - val_mae: 19043.5469\n",
      "Epoch 693/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 263685316.6545 - mae: 11898.0146 - val_loss: 921134444.2182 - val_mae: 20042.2344\n",
      "Epoch 694/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 318070678.4000 - mae: 13213.9502 - val_loss: 906600070.9818 - val_mae: 18687.2539\n",
      "Epoch 695/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 269712949.5273 - mae: 12209.3457 - val_loss: 873400443.3455 - val_mae: 18914.4805\n",
      "Epoch 696/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 294976919.8545 - mae: 12705.5596 - val_loss: 917739634.0364 - val_mae: 18902.8867\n",
      "Epoch 697/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 298799781.5273 - mae: 12682.3418 - val_loss: 912525714.6182 - val_mae: 19582.4082\n",
      "Epoch 698/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 298066036.3636 - mae: 12854.5410 - val_loss: 893765222.4000 - val_mae: 18690.0215\n",
      "Epoch 699/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 266309726.2545 - mae: 11836.1895 - val_loss: 893118363.9273 - val_mae: 18944.7480\n",
      "Epoch 700/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 270746976.2909 - mae: 12042.6504 - val_loss: 975337069.3818 - val_mae: 21208.6914\n",
      "Epoch 701/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 272731307.9273 - mae: 11935.8760 - val_loss: 939271938.3273 - val_mae: 19154.9941\n",
      "Epoch 702/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 293054582.6909 - mae: 12633.1621 - val_loss: 970715884.2182 - val_mae: 20997.1992\n",
      "Epoch 703/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 278503387.3455 - mae: 12200.4404 - val_loss: 945171921.4545 - val_mae: 18868.0059\n",
      "Epoch 704/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 291399442.6182 - mae: 12799.4521 - val_loss: 960816508.5091 - val_mae: 21202.4082\n",
      "Epoch 705/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 272695767.5636 - mae: 11896.1846 - val_loss: 887772517.2364 - val_mae: 18829.1914\n",
      "Epoch 706/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 249560470.6909 - mae: 11557.1855 - val_loss: 926804591.7091 - val_mae: 19957.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 248195371.6364 - mae: 11453.7979 - val_loss: 948741672.7273 - val_mae: 20582.1230\n",
      "Epoch 708/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 251747894.6909 - mae: 11808.0596 - val_loss: 888625530.1818 - val_mae: 18889.2324\n",
      "Epoch 709/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 250885422.5455 - mae: 11559.2705 - val_loss: 959228449.7455 - val_mae: 20755.0508\n",
      "Epoch 710/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 256670065.7455 - mae: 11860.3896 - val_loss: 916562707.7818 - val_mae: 18853.4316\n",
      "Epoch 711/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 265157314.0364 - mae: 12042.2227 - val_loss: 911525879.8545 - val_mae: 19760.2109\n",
      "Epoch 712/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 242016224.2909 - mae: 11387.9219 - val_loss: 905284801.1636 - val_mae: 18807.5527\n",
      "Epoch 713/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 340064397.3818 - mae: 13936.8584 - val_loss: 877239953.4545 - val_mae: 18739.3633\n",
      "Epoch 714/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 291241172.3636 - mae: 12794.8340 - val_loss: 901094376.7273 - val_mae: 18580.8984\n",
      "Epoch 715/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 275914750.2545 - mae: 12344.5791 - val_loss: 889640095.4182 - val_mae: 18972.8027\n",
      "Epoch 716/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 244474242.3273 - mae: 11449.9590 - val_loss: 894217577.8909 - val_mae: 18642.6309\n",
      "Epoch 717/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 243964634.1818 - mae: 11488.6162 - val_loss: 864766373.2364 - val_mae: 18872.5293\n",
      "Epoch 718/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 232286444.5091 - mae: 11092.1094 - val_loss: 888695366.9818 - val_mae: 18916.1328\n",
      "Epoch 719/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 229270714.4727 - mae: 11091.2871 - val_loss: 955124749.9636 - val_mae: 20950.1719\n",
      "Epoch 720/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 249434690.6182 - mae: 11712.7979 - val_loss: 926063222.6909 - val_mae: 18785.0527\n",
      "Epoch 721/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 247436296.7273 - mae: 11608.2637 - val_loss: 961180057.6000 - val_mae: 20758.6309\n",
      "Epoch 722/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 292607914.4727 - mae: 12799.1855 - val_loss: 904409647.7091 - val_mae: 18730.1699\n",
      "Epoch 723/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 278979739.0545 - mae: 12219.2979 - val_loss: 903378123.6364 - val_mae: 19566.2227\n",
      "Epoch 724/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 245013908.9455 - mae: 11311.6484 - val_loss: 899332870.9818 - val_mae: 18779.3691\n",
      "Epoch 725/1000\n",
      "880/880 [==============================] - 0s 71us/step - loss: 274012909.0909 - mae: 12240.7451 - val_loss: 912177513.8909 - val_mae: 19584.4160\n",
      "Epoch 726/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 260787873.1636 - mae: 11798.8477 - val_loss: 943585311.4182 - val_mae: 19168.5410\n",
      "Epoch 727/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 267605998.8364 - mae: 12050.3760 - val_loss: 914916233.3091 - val_mae: 19936.9277\n",
      "Epoch 728/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 235337126.4000 - mae: 11230.9600 - val_loss: 910536841.3091 - val_mae: 19248.8340\n",
      "Epoch 729/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 254269845.5273 - mae: 11769.1895 - val_loss: 904926004.3636 - val_mae: 19755.1504\n",
      "Epoch 730/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 257844125.6727 - mae: 11778.7529 - val_loss: 903529875.7818 - val_mae: 18951.4160\n",
      "Epoch 731/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 235335752.7273 - mae: 11105.2334 - val_loss: 934703845.2364 - val_mae: 20429.1191\n",
      "Epoch 732/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 228963826.0364 - mae: 10986.9023 - val_loss: 891853556.3636 - val_mae: 18944.6680\n",
      "Epoch 733/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 225432254.2545 - mae: 11014.6650 - val_loss: 908323297.7455 - val_mae: 19111.0449\n",
      "Epoch 734/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 220920345.0182 - mae: 10874.0293 - val_loss: 932724279.8545 - val_mae: 19169.5977\n",
      "Epoch 735/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 224786006.4000 - mae: 11030.1182 - val_loss: 910865092.6545 - val_mae: 19787.5957\n",
      "Epoch 736/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 239935463.8545 - mae: 11444.9980 - val_loss: 894734367.4182 - val_mae: 18912.6074\n",
      "Epoch 737/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 231414403.2000 - mae: 11283.3779 - val_loss: 912361133.3818 - val_mae: 18886.5996\n",
      "Epoch 738/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 229652927.1273 - mae: 10961.4355 - val_loss: 882995428.0727 - val_mae: 19406.5234\n",
      "Epoch 739/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 222538151.8545 - mae: 10823.1602 - val_loss: 912850205.0909 - val_mae: 19059.9434\n",
      "Epoch 740/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 217212115.2000 - mae: 10817.5166 - val_loss: 915632471.2727 - val_mae: 19843.3047\n",
      "Epoch 741/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 218044244.9455 - mae: 10737.1084 - val_loss: 912662600.1455 - val_mae: 19065.3379\n",
      "Epoch 742/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 216515250.9091 - mae: 10772.9082 - val_loss: 888520593.4545 - val_mae: 19242.0137\n",
      "Epoch 743/1000\n",
      "880/880 [==============================] - 0s 68us/step - loss: 231170629.2364 - mae: 11144.7646 - val_loss: 908512166.4000 - val_mae: 18841.7090\n",
      "Epoch 744/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 243210147.4909 - mae: 11555.5117 - val_loss: 962773662.2545 - val_mae: 20790.1406\n",
      "Epoch 745/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 226656470.4000 - mae: 11003.2998 - val_loss: 915311377.4545 - val_mae: 19679.6094\n",
      "Epoch 746/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 235310473.8909 - mae: 11232.0225 - val_loss: 967547431.5636 - val_mae: 19499.7793\n",
      "Epoch 747/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 324653662.2545 - mae: 13358.9854 - val_loss: 924525765.8182 - val_mae: 19983.1836\n",
      "Epoch 748/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 259306933.5273 - mae: 11519.0469 - val_loss: 919476308.9455 - val_mae: 19240.3594\n",
      "Epoch 749/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 281822361.6000 - mae: 12077.6250 - val_loss: 1022272109.3818 - val_mae: 22425.4355\n",
      "Epoch 750/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 282403344.0000 - mae: 12309.2832 - val_loss: 911551105.1636 - val_mae: 19084.7188\n",
      "Epoch 751/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 278957490.6182 - mae: 12195.2861 - val_loss: 1000537470.8364 - val_mae: 21927.4609\n",
      "Epoch 752/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 269905766.9818 - mae: 12096.3066 - val_loss: 864128175.7091 - val_mae: 18592.1289\n",
      "Epoch 753/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 225202077.3818 - mae: 10859.8281 - val_loss: 897346466.9091 - val_mae: 18960.5273\n",
      "Epoch 754/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 215053265.4545 - mae: 10650.1816 - val_loss: 897965038.5455 - val_mae: 19440.9727\n",
      "Epoch 755/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 217936046.5455 - mae: 10716.4424 - val_loss: 903691915.6364 - val_mae: 18866.7734\n",
      "Epoch 756/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 252821672.1455 - mae: 11711.0674 - val_loss: 1075125188.6545 - val_mae: 22900.2598\n",
      "Epoch 757/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 252400649.0182 - mae: 11667.7705 - val_loss: 910039121.4545 - val_mae: 19068.4082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 758/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 246993298.0364 - mae: 11422.0303 - val_loss: 988012098.3273 - val_mae: 21380.2129\n",
      "Epoch 759/1000\n",
      "880/880 [==============================] - 0s 101us/step - loss: 227323810.3273 - mae: 11086.4229 - val_loss: 915661544.7273 - val_mae: 19688.7227\n",
      "Epoch 760/1000\n",
      "880/880 [==============================] - 0s 84us/step - loss: 235571125.8182 - mae: 11346.1826 - val_loss: 916859799.2727 - val_mae: 19021.9414\n",
      "Epoch 761/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 251173892.6545 - mae: 11559.1338 - val_loss: 961507260.5091 - val_mae: 20501.3359\n",
      "Epoch 762/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 227005420.5091 - mae: 11008.5654 - val_loss: 911026141.0909 - val_mae: 19771.5391\n",
      "Epoch 763/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 224965530.1818 - mae: 10939.1094 - val_loss: 912530007.2727 - val_mae: 18911.2227\n",
      "Epoch 764/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 231159289.6000 - mae: 11144.1943 - val_loss: 1003800793.6000 - val_mae: 21301.5723\n",
      "Epoch 765/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 267997446.4000 - mae: 12012.6641 - val_loss: 987068481.1636 - val_mae: 19793.4805\n",
      "Epoch 766/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 290413235.2000 - mae: 12616.0742 - val_loss: 973022786.3273 - val_mae: 20983.7324\n",
      "Epoch 767/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 317807473.4545 - mae: 13218.7109 - val_loss: 879434764.8000 - val_mae: 18838.0820\n",
      "Epoch 768/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 290728929.1636 - mae: 12556.9707 - val_loss: 893177110.1091 - val_mae: 19504.4902\n",
      "Epoch 769/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 315094892.8000 - mae: 13118.9678 - val_loss: 911651667.7818 - val_mae: 19131.0781\n",
      "Epoch 770/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 274430508.5091 - mae: 12216.9629 - val_loss: 897486260.3636 - val_mae: 19520.1406\n",
      "Epoch 771/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 255253089.1636 - mae: 11304.8760 - val_loss: 898160999.5636 - val_mae: 19280.0234\n",
      "Epoch 772/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 235728679.2727 - mae: 11243.5977 - val_loss: 920532628.9455 - val_mae: 19839.7363\n",
      "Epoch 773/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 264520285.0909 - mae: 12010.5088 - val_loss: 984603001.0182 - val_mae: 21453.6895\n",
      "Epoch 774/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 269879955.4909 - mae: 12237.9180 - val_loss: 920369184.5818 - val_mae: 18890.9062\n",
      "Epoch 775/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 243243958.9818 - mae: 11425.1553 - val_loss: 907171499.0545 - val_mae: 19717.6445\n",
      "Epoch 776/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 257619865.3091 - mae: 11841.5527 - val_loss: 900259609.6000 - val_mae: 18962.6387\n",
      "Epoch 777/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 220053026.6182 - mae: 10790.0791 - val_loss: 886073384.7273 - val_mae: 19488.4219\n",
      "Epoch 778/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 238421652.9455 - mae: 11393.8291 - val_loss: 929820847.7091 - val_mae: 19513.3594\n",
      "Epoch 779/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 250295850.4727 - mae: 11756.6729 - val_loss: 894644594.0364 - val_mae: 19117.4453\n",
      "Epoch 780/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 251804096.8727 - mae: 11732.5703 - val_loss: 905485863.5636 - val_mae: 19037.6816\n",
      "Epoch 781/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 234781084.8000 - mae: 11123.3955 - val_loss: 933012457.8909 - val_mae: 19189.3320\n",
      "Epoch 782/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 210710038.9818 - mae: 10639.9238 - val_loss: 899049149.6727 - val_mae: 19494.7461\n",
      "Epoch 783/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 208648068.6545 - mae: 10519.5293 - val_loss: 922251833.0182 - val_mae: 18959.8906\n",
      "Epoch 784/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 218649665.1636 - mae: 10731.6055 - val_loss: 927317426.0364 - val_mae: 20134.8691\n",
      "Epoch 785/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 210667368.7273 - mae: 10693.8076 - val_loss: 933494294.1091 - val_mae: 19208.0859\n",
      "Epoch 786/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 207338756.6545 - mae: 10509.5303 - val_loss: 937715514.1818 - val_mae: 20420.6133\n",
      "Epoch 787/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 215035469.9636 - mae: 10893.3398 - val_loss: 931648116.3636 - val_mae: 20021.8047\n",
      "Epoch 788/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 206421978.7636 - mae: 10589.2783 - val_loss: 921400001.1636 - val_mae: 18989.3301\n",
      "Epoch 789/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 201765209.0182 - mae: 10395.3896 - val_loss: 946340708.0727 - val_mae: 20137.9727\n",
      "Epoch 790/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 193954071.5636 - mae: 10069.8955 - val_loss: 911035257.0182 - val_mae: 19157.8281\n",
      "Epoch 791/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 200237463.5636 - mae: 10401.8975 - val_loss: 913216816.8727 - val_mae: 19356.9395\n",
      "Epoch 792/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 192698610.0364 - mae: 10098.9033 - val_loss: 920120477.0909 - val_mae: 19775.4863\n",
      "Epoch 793/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 195699554.0364 - mae: 10140.9736 - val_loss: 916421626.1818 - val_mae: 19274.5117\n",
      "Epoch 794/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 194878773.9636 - mae: 10237.8691 - val_loss: 955145538.3273 - val_mae: 20515.0449\n",
      "Epoch 795/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 216993554.3273 - mae: 10911.2070 - val_loss: 918521733.8182 - val_mae: 19150.5234\n",
      "Epoch 796/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 209272547.4909 - mae: 10594.0947 - val_loss: 940340681.3091 - val_mae: 19391.2051\n",
      "Epoch 797/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 229916296.4364 - mae: 11307.8535 - val_loss: 938158557.0909 - val_mae: 20184.0254\n",
      "Epoch 798/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 193671793.1636 - mae: 10168.0146 - val_loss: 901881305.6000 - val_mae: 18988.5684\n",
      "Epoch 799/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 231128749.3818 - mae: 11275.0400 - val_loss: 938619351.2727 - val_mae: 19174.4141\n",
      "Epoch 800/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 237507152.5818 - mae: 11555.2871 - val_loss: 989248863.4182 - val_mae: 21240.3203\n",
      "Epoch 801/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 248720769.4545 - mae: 11578.2090 - val_loss: 951099851.6364 - val_mae: 20321.0723\n",
      "Epoch 802/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 217142911.4182 - mae: 10715.9941 - val_loss: 885669672.7273 - val_mae: 19199.8086\n",
      "Epoch 803/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 200597345.1636 - mae: 10311.4814 - val_loss: 993679035.3455 - val_mae: 21294.5371\n",
      "Epoch 804/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 219847608.4364 - mae: 10856.7686 - val_loss: 890484185.6000 - val_mae: 19539.2773\n",
      "Epoch 805/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 227400926.8364 - mae: 11189.9668 - val_loss: 921612092.5091 - val_mae: 19674.7949\n",
      "Epoch 806/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 225016796.2182 - mae: 10878.3682 - val_loss: 927311823.1273 - val_mae: 19837.9902\n",
      "Epoch 807/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 236754210.9091 - mae: 11303.5059 - val_loss: 948154306.3273 - val_mae: 19691.5879\n",
      "Epoch 808/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 216643408.5818 - mae: 10962.8047 - val_loss: 924238394.1818 - val_mae: 19772.8770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 204742867.9273 - mae: 10451.3447 - val_loss: 919930425.0182 - val_mae: 19919.7949\n",
      "Epoch 810/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 201874701.6727 - mae: 10304.3945 - val_loss: 966892446.2545 - val_mae: 20454.0918\n",
      "Epoch 811/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 193093784.1455 - mae: 10201.0947 - val_loss: 911076860.5091 - val_mae: 19267.4453\n",
      "Epoch 812/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 196287982.5455 - mae: 10401.2070 - val_loss: 918456254.8364 - val_mae: 19809.6641\n",
      "Epoch 813/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 193407765.5273 - mae: 10180.9473 - val_loss: 962449894.4000 - val_mae: 20615.9844\n",
      "Epoch 814/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 200682600.1455 - mae: 10404.0566 - val_loss: 942511561.3091 - val_mae: 19316.9160\n",
      "Epoch 815/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 204604909.0909 - mae: 10534.6113 - val_loss: 950277431.8545 - val_mae: 20259.9629\n",
      "Epoch 816/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 261428852.9455 - mae: 12149.8096 - val_loss: 1007179963.3455 - val_mae: 21502.4863\n",
      "Epoch 817/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 270367362.0364 - mae: 12437.1406 - val_loss: 1076579823.7091 - val_mae: 20806.5410\n",
      "Epoch 818/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 338160960.5818 - mae: 13982.4512 - val_loss: 994944009.3091 - val_mae: 21592.5469\n",
      "Epoch 819/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 245141792.5818 - mae: 11652.5117 - val_loss: 894069481.8909 - val_mae: 19052.9277\n",
      "Epoch 820/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 264182141.0909 - mae: 12055.4072 - val_loss: 959662266.1818 - val_mae: 20381.9805\n",
      "Epoch 821/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 213980674.0364 - mae: 10519.0322 - val_loss: 911296797.0909 - val_mae: 19461.0918\n",
      "Epoch 822/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 282927211.6364 - mae: 11748.4238 - val_loss: 970084797.6727 - val_mae: 19210.6094\n",
      "Epoch 823/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 296067476.6545 - mae: 12700.2979 - val_loss: 997850999.8545 - val_mae: 22128.3867\n",
      "Epoch 824/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 254501205.5273 - mae: 11603.3203 - val_loss: 925638906.1818 - val_mae: 19470.2070\n",
      "Epoch 825/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 369468820.3636 - mae: 12600.5645 - val_loss: 1186551363.4909 - val_mae: 24844.1309\n",
      "Epoch 826/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 332575475.7818 - mae: 12985.5137 - val_loss: 998067376.8727 - val_mae: 20224.3281\n",
      "Epoch 827/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 440606414.5455 - mae: 13791.4629 - val_loss: 1093599627.6364 - val_mae: 21122.4805\n",
      "Epoch 828/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 409904012.2182 - mae: 14905.8750 - val_loss: 1209152486.4000 - val_mae: 25117.6270\n",
      "Epoch 829/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 532952287.4182 - mae: 16441.8828 - val_loss: 929372052.9455 - val_mae: 19117.1914\n",
      "Epoch 830/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 534068709.2364 - mae: 16021.0781 - val_loss: 856695042.3273 - val_mae: 18801.1094\n",
      "Epoch 831/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 512958854.9818 - mae: 16490.2715 - val_loss: 922417115.9273 - val_mae: 18644.4492\n",
      "Epoch 832/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 382135755.6364 - mae: 14227.1436 - val_loss: 907013760.0000 - val_mae: 19660.6094\n",
      "Epoch 833/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 318525774.5455 - mae: 12747.9160 - val_loss: 1015748788.3636 - val_mae: 21748.4453\n",
      "Epoch 834/1000\n",
      "880/880 [==============================] - 0s 92us/step - loss: 293752042.4727 - mae: 12633.6514 - val_loss: 920235578.1818 - val_mae: 19327.8379\n",
      "Epoch 835/1000\n",
      "880/880 [==============================] - 0s 91us/step - loss: 284989653.5273 - mae: 12532.2832 - val_loss: 869610600.7273 - val_mae: 18879.3223\n",
      "Epoch 836/1000\n",
      "880/880 [==============================] - 0s 98us/step - loss: 266936738.3273 - mae: 11925.4082 - val_loss: 923580823.2727 - val_mae: 20334.9727\n",
      "Epoch 837/1000\n",
      "880/880 [==============================] - 0s 92us/step - loss: 250435626.4727 - mae: 11741.2842 - val_loss: 886121797.8182 - val_mae: 18564.6621\n",
      "Epoch 838/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 240616336.5818 - mae: 11341.4307 - val_loss: 949260817.4545 - val_mae: 20791.5098\n",
      "Epoch 839/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 228894384.2909 - mae: 11450.4902 - val_loss: 883900740.6545 - val_mae: 18824.5020\n",
      "Epoch 840/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 232438325.8182 - mae: 11070.9111 - val_loss: 879373929.8909 - val_mae: 18828.5059\n",
      "Epoch 841/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 221081389.9636 - mae: 10901.8359 - val_loss: 897132875.6364 - val_mae: 18995.0527\n",
      "Epoch 842/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 224152908.2182 - mae: 11079.2627 - val_loss: 886424083.7818 - val_mae: 19103.9004\n",
      "Epoch 843/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 230234823.5636 - mae: 11325.1650 - val_loss: 898417856.0000 - val_mae: 18827.6738\n",
      "Epoch 844/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 236803180.5091 - mae: 11494.7627 - val_loss: 909152710.9818 - val_mae: 19468.9824\n",
      "Epoch 845/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 202090559.4182 - mae: 10267.1436 - val_loss: 891009964.2182 - val_mae: 19000.0391\n",
      "Epoch 846/1000\n",
      "880/880 [==============================] - 0s 134us/step - loss: 193848836.9455 - mae: 10142.3652 - val_loss: 895647993.0182 - val_mae: 19148.3047\n",
      "Epoch 847/1000\n",
      "880/880 [==============================] - 0s 97us/step - loss: 186952115.4909 - mae: 9899.6016 - val_loss: 888749867.0545 - val_mae: 18969.3789\n",
      "Epoch 848/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 199419699.4909 - mae: 10292.4717 - val_loss: 919608257.1636 - val_mae: 19381.4062\n",
      "Epoch 849/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 188901114.1818 - mae: 9916.8984 - val_loss: 932197882.1818 - val_mae: 19944.3457\n",
      "Epoch 850/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 189934584.1455 - mae: 10011.3584 - val_loss: 906841483.6364 - val_mae: 19330.6582\n",
      "Epoch 851/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 182037848.4364 - mae: 9801.9658 - val_loss: 982141417.8909 - val_mae: 21143.7793\n",
      "Epoch 852/1000\n",
      "880/880 [==============================] - 0s 89us/step - loss: 247985841.4545 - mae: 11849.2070 - val_loss: 914966725.8182 - val_mae: 19322.6230\n",
      "Epoch 853/1000\n",
      "880/880 [==============================] - 0s 87us/step - loss: 223256610.3273 - mae: 10987.8418 - val_loss: 951048828.5091 - val_mae: 20179.0918\n",
      "Epoch 854/1000\n",
      "880/880 [==============================] - 0s 85us/step - loss: 191150630.6909 - mae: 10104.6816 - val_loss: 886081499.9273 - val_mae: 19088.8320\n",
      "Epoch 855/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 180356306.9091 - mae: 9774.5430 - val_loss: 901945147.3455 - val_mae: 19352.7637\n",
      "Epoch 856/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 184836893.6727 - mae: 9944.4873 - val_loss: 928599647.4182 - val_mae: 19957.4219\n",
      "Epoch 857/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 178219613.9636 - mae: 9748.6045 - val_loss: 888980973.3818 - val_mae: 19328.4355\n",
      "Epoch 858/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 180749866.1818 - mae: 9833.5225 - val_loss: 980222838.6909 - val_mae: 20944.6777\n",
      "Epoch 859/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 207002565.5273 - mae: 10589.0322 - val_loss: 910888587.6364 - val_mae: 19191.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 860/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 183985378.6182 - mae: 9876.7402 - val_loss: 923427194.1818 - val_mae: 19338.7480\n",
      "Epoch 861/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 178195542.9818 - mae: 9786.1152 - val_loss: 938800828.5091 - val_mae: 20017.5586\n",
      "Epoch 862/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 174112482.0364 - mae: 9596.7793 - val_loss: 918098358.6909 - val_mae: 19806.1641\n",
      "Epoch 863/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 169532407.5636 - mae: 9455.8486 - val_loss: 923173278.2545 - val_mae: 19260.3418\n",
      "Epoch 864/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 184996851.7818 - mae: 9945.7305 - val_loss: 906562814.8364 - val_mae: 19506.8516\n",
      "Epoch 865/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 231385761.1636 - mae: 11393.4453 - val_loss: 1066247888.2909 - val_mae: 22784.1094\n",
      "Epoch 866/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 219325222.9818 - mae: 10792.7588 - val_loss: 951322655.4182 - val_mae: 19687.0176\n",
      "Epoch 867/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 213661566.2545 - mae: 10790.7100 - val_loss: 976254863.1273 - val_mae: 21128.1055\n",
      "Epoch 868/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 264554800.8727 - mae: 12302.5684 - val_loss: 909014042.7636 - val_mae: 19340.4551\n",
      "Epoch 869/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 250727120.2909 - mae: 11982.1182 - val_loss: 911389671.5636 - val_mae: 19361.3164\n",
      "Epoch 870/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 245978946.9091 - mae: 11559.6943 - val_loss: 893784572.5091 - val_mae: 19795.2930\n",
      "Epoch 871/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 216355114.4727 - mae: 10822.6953 - val_loss: 950437851.9273 - val_mae: 19411.8047\n",
      "Epoch 872/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 214664890.1818 - mae: 10808.0791 - val_loss: 969577978.1818 - val_mae: 21181.7676\n",
      "Epoch 873/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 207349726.2545 - mae: 10517.7441 - val_loss: 903104538.7636 - val_mae: 19152.1309\n",
      "Epoch 874/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 198304248.1455 - mae: 10474.1338 - val_loss: 964571539.7818 - val_mae: 20898.2637\n",
      "Epoch 875/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 221095066.7636 - mae: 11053.8027 - val_loss: 939800922.7636 - val_mae: 19291.4961\n",
      "Epoch 876/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 209933776.2909 - mae: 10852.2656 - val_loss: 1045551916.2182 - val_mae: 22147.2539\n",
      "Epoch 877/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 227468376.7273 - mae: 11473.5049 - val_loss: 989829078.1091 - val_mae: 20164.4551\n",
      "Epoch 878/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 243704845.3818 - mae: 11761.6318 - val_loss: 953997082.7636 - val_mae: 20636.5957\n",
      "Epoch 879/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 216517677.9636 - mae: 10929.8906 - val_loss: 913072808.7273 - val_mae: 19453.9141\n",
      "Epoch 880/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 196107673.6000 - mae: 10157.3633 - val_loss: 913821594.7636 - val_mae: 19138.4727\n",
      "Epoch 881/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 182822012.5091 - mae: 9828.0234 - val_loss: 932108389.2364 - val_mae: 20233.7969\n",
      "Epoch 882/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 176468102.4000 - mae: 9672.3896 - val_loss: 902362400.5818 - val_mae: 19119.8633\n",
      "Epoch 883/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 168249270.1091 - mae: 9420.2637 - val_loss: 920257444.0727 - val_mae: 19934.3496\n",
      "Epoch 884/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 165376292.9455 - mae: 9309.6436 - val_loss: 949787899.3455 - val_mae: 20292.4219\n",
      "Epoch 885/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 170714372.0727 - mae: 9665.4971 - val_loss: 925943400.7273 - val_mae: 19327.6387\n",
      "Epoch 886/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 186310147.7818 - mae: 9973.7061 - val_loss: 924484706.9091 - val_mae: 19675.5703\n",
      "Epoch 887/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 176480952.4364 - mae: 9756.3496 - val_loss: 949987067.3455 - val_mae: 20465.0918\n",
      "Epoch 888/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 186102983.8545 - mae: 10207.5000 - val_loss: 943059353.6000 - val_mae: 19511.2910\n",
      "Epoch 889/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 176121481.3091 - mae: 9765.9814 - val_loss: 900259699.2000 - val_mae: 19497.8086\n",
      "Epoch 890/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 182819140.3636 - mae: 9853.2441 - val_loss: 956880708.6545 - val_mae: 20596.3203\n",
      "Epoch 891/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 180284913.7455 - mae: 10006.9541 - val_loss: 930130334.2545 - val_mae: 19325.4531\n",
      "Epoch 892/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 194094683.6364 - mae: 10287.7158 - val_loss: 924316729.0182 - val_mae: 19423.9551\n",
      "Epoch 893/1000\n",
      "880/880 [==============================] - 0s 83us/step - loss: 178548310.9818 - mae: 9941.0645 - val_loss: 984365323.6364 - val_mae: 20773.8164\n",
      "Epoch 894/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 197851752.4364 - mae: 10576.7383 - val_loss: 911778728.7273 - val_mae: 19571.3516\n",
      "Epoch 895/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 170292048.5818 - mae: 9460.8291 - val_loss: 941472537.6000 - val_mae: 20348.3047\n",
      "Epoch 896/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 177805439.7091 - mae: 9784.7070 - val_loss: 918377936.2909 - val_mae: 19256.9492\n",
      "Epoch 897/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 165739584.2909 - mae: 9384.4072 - val_loss: 952580173.9636 - val_mae: 20630.5371\n",
      "Epoch 898/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 166800403.7818 - mae: 9480.1260 - val_loss: 908957349.2364 - val_mae: 19517.0449\n",
      "Epoch 899/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 161164778.7636 - mae: 9218.3027 - val_loss: 941315236.0727 - val_mae: 19278.2402\n",
      "Epoch 900/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 184071302.1091 - mae: 10245.2217 - val_loss: 1062485948.5091 - val_mae: 22697.0020\n",
      "Epoch 901/1000\n",
      "880/880 [==============================] - 0s 86us/step - loss: 244064342.6909 - mae: 11995.5957 - val_loss: 940176474.7636 - val_mae: 19784.4941\n",
      "Epoch 902/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 220450282.4727 - mae: 11077.8223 - val_loss: 935198766.5455 - val_mae: 19442.4277\n",
      "Epoch 903/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 193518811.9273 - mae: 10389.4346 - val_loss: 959763471.1273 - val_mae: 20442.0469\n",
      "Epoch 904/1000\n",
      "880/880 [==============================] - 0s 79us/step - loss: 164727920.7273 - mae: 9246.3525 - val_loss: 966467731.7818 - val_mae: 20620.1914\n",
      "Epoch 905/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 169880209.1636 - mae: 9523.6162 - val_loss: 931611449.0182 - val_mae: 19942.7383\n",
      "Epoch 906/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 162000798.1091 - mae: 9266.0791 - val_loss: 915382131.2000 - val_mae: 19401.2910\n",
      "Epoch 907/1000\n",
      "880/880 [==============================] - 0s 84us/step - loss: 160060660.9455 - mae: 9172.0762 - val_loss: 929439086.5455 - val_mae: 19606.2598\n",
      "Epoch 908/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 155083306.9091 - mae: 9058.1133 - val_loss: 912975302.9818 - val_mae: 19460.6699\n",
      "Epoch 909/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 157704657.7455 - mae: 9124.5264 - val_loss: 956380546.3273 - val_mae: 20385.4668\n",
      "Epoch 910/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 173968642.3273 - mae: 9575.8564 - val_loss: 952103994.1818 - val_mae: 20317.2734\n",
      "Epoch 911/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 0s 79us/step - loss: 163784121.0182 - mae: 9409.1299 - val_loss: 928904841.3091 - val_mae: 19969.9844\n",
      "Epoch 912/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 162272362.0364 - mae: 9243.3799 - val_loss: 953279397.2364 - val_mae: 20286.3457\n",
      "Epoch 913/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 168753007.7091 - mae: 9614.0977 - val_loss: 927175245.9636 - val_mae: 19685.4414\n",
      "Epoch 914/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 159338906.6182 - mae: 9302.5879 - val_loss: 907790744.4364 - val_mae: 19429.2676\n",
      "Epoch 915/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 180912612.6545 - mae: 9951.7773 - val_loss: 939825271.8545 - val_mae: 20292.0039\n",
      "Epoch 916/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 176352289.1636 - mae: 9823.7510 - val_loss: 1042459396.6545 - val_mae: 22463.2246\n",
      "Epoch 917/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 184969871.4182 - mae: 10187.8291 - val_loss: 934203465.3091 - val_mae: 19498.4062\n",
      "Epoch 918/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 188677121.4545 - mae: 10375.6680 - val_loss: 923585043.7818 - val_mae: 19304.3008\n",
      "Epoch 919/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 231893001.3091 - mae: 11555.6641 - val_loss: 936223584.5818 - val_mae: 20659.6133\n",
      "Epoch 920/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 266508005.8182 - mae: 12415.3057 - val_loss: 993191476.3636 - val_mae: 20793.8301\n",
      "Epoch 921/1000\n",
      "880/880 [==============================] - 0s 89us/step - loss: 189084714.1818 - mae: 10162.9521 - val_loss: 948502372.0727 - val_mae: 19436.7637\n",
      "Epoch 922/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 231177401.6000 - mae: 11414.7920 - val_loss: 1010801209.0182 - val_mae: 21665.6270\n",
      "Epoch 923/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 221436609.1636 - mae: 11251.4717 - val_loss: 887013676.2182 - val_mae: 19508.4062\n",
      "Epoch 924/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 211978497.7455 - mae: 10996.3633 - val_loss: 904511649.7455 - val_mae: 19294.9004\n",
      "Epoch 925/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 201929643.3455 - mae: 10744.0469 - val_loss: 986156460.2182 - val_mae: 21521.8770\n",
      "Epoch 926/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 215656490.4727 - mae: 10952.3242 - val_loss: 913207883.6364 - val_mae: 19403.5801\n",
      "Epoch 927/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 198972232.4364 - mae: 10259.7598 - val_loss: 909022366.2545 - val_mae: 19234.9316\n",
      "Epoch 928/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 162884857.4545 - mae: 9256.9473 - val_loss: 894055543.8545 - val_mae: 19611.6406\n",
      "Epoch 929/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 155063116.8000 - mae: 9019.9922 - val_loss: 937262468.6545 - val_mae: 20072.4453\n",
      "Epoch 930/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 159538802.6182 - mae: 9080.1328 - val_loss: 902126653.6727 - val_mae: 19609.9434\n",
      "Epoch 931/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 162256964.9455 - mae: 9328.7412 - val_loss: 930432578.3273 - val_mae: 19743.5234\n",
      "Epoch 932/1000\n",
      "880/880 [==============================] - 0s 82us/step - loss: 162324209.7455 - mae: 9324.6924 - val_loss: 975444519.5636 - val_mae: 20835.0918\n",
      "Epoch 933/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 192355646.8364 - mae: 10145.3525 - val_loss: 935177378.9091 - val_mae: 20065.3730\n",
      "Epoch 934/1000\n",
      "880/880 [==============================] - 0s 86us/step - loss: 181320392.1455 - mae: 9933.9170 - val_loss: 913869026.9091 - val_mae: 19534.8809\n",
      "Epoch 935/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 169468136.4364 - mae: 9621.3408 - val_loss: 985131492.0727 - val_mae: 21147.5059\n",
      "Epoch 936/1000\n",
      "880/880 [==============================] - 0s 107us/step - loss: 188946260.9455 - mae: 10285.9365 - val_loss: 918859109.2364 - val_mae: 19733.9316\n",
      "Epoch 937/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 175403801.3091 - mae: 9749.0557 - val_loss: 917026037.5273 - val_mae: 19446.4629\n",
      "Epoch 938/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 173376697.8909 - mae: 9570.8887 - val_loss: 962118662.9818 - val_mae: 20291.5449\n",
      "Epoch 939/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 203994896.5818 - mae: 10590.3867 - val_loss: 936995369.8909 - val_mae: 20118.8105\n",
      "Epoch 940/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 213030295.8545 - mae: 10939.5098 - val_loss: 935530171.3455 - val_mae: 19390.9219\n",
      "Epoch 941/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 221734866.3273 - mae: 11169.5537 - val_loss: 899171606.1091 - val_mae: 19755.5957\n",
      "Epoch 942/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 193453192.7273 - mae: 10202.3945 - val_loss: 1028692719.7091 - val_mae: 21727.4844\n",
      "Epoch 943/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 194525467.9273 - mae: 10453.3105 - val_loss: 962610155.0545 - val_mae: 19683.9434\n",
      "Epoch 944/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 181599841.7455 - mae: 9938.6064 - val_loss: 994372698.7636 - val_mae: 21334.7441\n",
      "Epoch 945/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 164162979.4909 - mae: 9446.0459 - val_loss: 913420035.4909 - val_mae: 19590.3574\n",
      "Epoch 946/1000\n",
      "880/880 [==============================] - 0s 69us/step - loss: 155125621.8182 - mae: 9048.5049 - val_loss: 944616864.5818 - val_mae: 20260.0254\n",
      "Epoch 947/1000\n",
      "880/880 [==============================] - 0s 76us/step - loss: 153406338.1818 - mae: 8980.0479 - val_loss: 918077893.8182 - val_mae: 19784.5371\n",
      "Epoch 948/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 154082822.1091 - mae: 9130.8662 - val_loss: 928694317.3818 - val_mae: 19394.0137\n",
      "Epoch 949/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 149011974.1091 - mae: 8904.3252 - val_loss: 969947348.9455 - val_mae: 20909.1680\n",
      "Epoch 950/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 152667617.4545 - mae: 8928.2637 - val_loss: 930348989.6727 - val_mae: 19708.0508\n",
      "Epoch 951/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 143170192.0000 - mae: 8713.6846 - val_loss: 927770479.7091 - val_mae: 19870.2598\n",
      "Epoch 952/1000\n",
      "880/880 [==============================] - 0s 72us/step - loss: 143759589.8182 - mae: 8694.5928 - val_loss: 915584243.2000 - val_mae: 19683.3105\n",
      "Epoch 953/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 159824974.8364 - mae: 9292.4287 - val_loss: 1013704596.9455 - val_mae: 19816.5859\n",
      "Epoch 954/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 199480786.0364 - mae: 10776.5234 - val_loss: 1023259248.8727 - val_mae: 21681.6289\n",
      "Epoch 955/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 227205306.7636 - mae: 11632.3398 - val_loss: 1027124640.5818 - val_mae: 21682.1191\n",
      "Epoch 956/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 236846712.7273 - mae: 11472.2725 - val_loss: 1030832530.6182 - val_mae: 20469.7871\n",
      "Epoch 957/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 247423533.0909 - mae: 12016.6035 - val_loss: 927188123.9273 - val_mae: 19587.9355\n",
      "Epoch 958/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 165981601.1636 - mae: 9464.4238 - val_loss: 950746201.6000 - val_mae: 19672.1953\n",
      "Epoch 959/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 178319042.9091 - mae: 9857.8271 - val_loss: 961713654.6909 - val_mae: 19331.7461\n",
      "Epoch 960/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 220627252.3636 - mae: 11132.0947 - val_loss: 919815034.1818 - val_mae: 20260.2676\n",
      "Epoch 961/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 196503019.9273 - mae: 10545.9697 - val_loss: 980886581.5273 - val_mae: 20252.3594\n",
      "Epoch 962/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 188664758.6909 - mae: 10002.8271 - val_loss: 882384307.2000 - val_mae: 19356.9062\n",
      "Epoch 963/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 162604273.4545 - mae: 9175.7773 - val_loss: 981454971.3455 - val_mae: 20504.9316\n",
      "Epoch 964/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 153433243.3455 - mae: 9046.0908 - val_loss: 894635728.2909 - val_mae: 19453.2617\n",
      "Epoch 965/1000\n",
      "880/880 [==============================] - 0s 75us/step - loss: 167859323.3455 - mae: 9535.0293 - val_loss: 939501683.2000 - val_mae: 19845.7031\n",
      "Epoch 966/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 169270096.0000 - mae: 9605.2520 - val_loss: 983227860.9455 - val_mae: 20705.1777\n",
      "Epoch 967/1000\n",
      "880/880 [==============================] - 0s 74us/step - loss: 171587092.3636 - mae: 9714.9912 - val_loss: 929094686.2545 - val_mae: 19543.6270\n",
      "Epoch 968/1000\n",
      "880/880 [==============================] - 0s 70us/step - loss: 170170670.8364 - mae: 9676.6318 - val_loss: 931635318.6909 - val_mae: 19540.0977\n",
      "Epoch 969/1000\n",
      "880/880 [==============================] - 0s 78us/step - loss: 179930936.1455 - mae: 9876.6543 - val_loss: 981799279.7091 - val_mae: 21338.6309\n",
      "Epoch 970/1000\n",
      "880/880 [==============================] - 0s 119us/step - loss: 176789499.9273 - mae: 10105.1406 - val_loss: 959835125.5273 - val_mae: 20362.1836\n",
      "Epoch 971/1000\n",
      "880/880 [==============================] - 0s 122us/step - loss: 148855721.1636 - mae: 8941.7910 - val_loss: 929119444.9455 - val_mae: 19455.9180\n",
      "Epoch 972/1000\n",
      "880/880 [==============================] - 0s 97us/step - loss: 153654432.5818 - mae: 9220.9180 - val_loss: 918675972.6545 - val_mae: 19439.8633\n",
      "Epoch 973/1000\n",
      "880/880 [==============================] - 0s 77us/step - loss: 147506683.0545 - mae: 8874.5713 - val_loss: 945585029.8182 - val_mae: 19672.7461\n",
      "Epoch 974/1000\n",
      "880/880 [==============================] - 0s 107us/step - loss: 148378503.1273 - mae: 8964.7988 - val_loss: 988326273.1636 - val_mae: 20990.5430\n",
      "Epoch 975/1000\n",
      "880/880 [==============================] - 0s 101us/step - loss: 157373174.1091 - mae: 9154.4775 - val_loss: 949828184.4364 - val_mae: 20140.5508\n",
      "Epoch 976/1000\n",
      "880/880 [==============================] - 0s 106us/step - loss: 165697307.0545 - mae: 9567.2588 - val_loss: 921129263.7091 - val_mae: 19632.9766\n",
      "Epoch 977/1000\n",
      "880/880 [==============================] - 0s 106us/step - loss: 171470577.4545 - mae: 9857.6953 - val_loss: 961811539.7818 - val_mae: 20468.9160\n",
      "Epoch 978/1000\n",
      "880/880 [==============================] - 0s 114us/step - loss: 152310575.4182 - mae: 8995.7021 - val_loss: 954990218.4727 - val_mae: 19867.2871\n",
      "Epoch 979/1000\n",
      "880/880 [==============================] - 0s 114us/step - loss: 175655367.5636 - mae: 9733.7988 - val_loss: 940570178.3273 - val_mae: 19733.0547\n",
      "Epoch 980/1000\n",
      "880/880 [==============================] - 0s 107us/step - loss: 164476097.7455 - mae: 9473.4746 - val_loss: 941367702.1091 - val_mae: 20063.4551\n",
      "Epoch 981/1000\n",
      "880/880 [==============================] - 0s 125us/step - loss: 148184560.0000 - mae: 8940.0615 - val_loss: 955380786.0364 - val_mae: 20244.4863\n",
      "Epoch 982/1000\n",
      "880/880 [==============================] - 0s 118us/step - loss: 150601705.6000 - mae: 8955.2402 - val_loss: 946774060.2182 - val_mae: 19617.3320\n",
      "Epoch 983/1000\n",
      "880/880 [==============================] - 0s 105us/step - loss: 159582261.8182 - mae: 9419.0645 - val_loss: 936674441.3091 - val_mae: 19703.0781\n",
      "Epoch 984/1000\n",
      "880/880 [==============================] - 0s 104us/step - loss: 144304128.1455 - mae: 8784.6094 - val_loss: 950358568.7273 - val_mae: 20490.9414\n",
      "Epoch 985/1000\n",
      "880/880 [==============================] - 0s 103us/step - loss: 140968657.1636 - mae: 8732.6914 - val_loss: 946626050.3273 - val_mae: 19665.5059\n",
      "Epoch 986/1000\n",
      "880/880 [==============================] - 0s 108us/step - loss: 145022282.1818 - mae: 8931.2090 - val_loss: 911643959.8545 - val_mae: 19606.2910\n",
      "Epoch 987/1000\n",
      "880/880 [==============================] - 0s 107us/step - loss: 159581436.3636 - mae: 9180.0840 - val_loss: 1039207732.3636 - val_mae: 21905.9473\n",
      "Epoch 988/1000\n",
      "880/880 [==============================] - 0s 108us/step - loss: 148332941.9636 - mae: 8970.1602 - val_loss: 937389445.8182 - val_mae: 19971.9492\n",
      "Epoch 989/1000\n",
      "880/880 [==============================] - 0s 101us/step - loss: 160131416.1455 - mae: 9289.5254 - val_loss: 948281907.2000 - val_mae: 19834.6543\n",
      "Epoch 990/1000\n",
      "880/880 [==============================] - 0s 101us/step - loss: 199028779.6364 - mae: 10562.2021 - val_loss: 984892128.5818 - val_mae: 21072.5000\n",
      "Epoch 991/1000\n",
      "880/880 [==============================] - 0s 98us/step - loss: 195636295.8545 - mae: 10416.1504 - val_loss: 984322803.2000 - val_mae: 20648.1641\n",
      "Epoch 992/1000\n",
      "880/880 [==============================] - 0s 112us/step - loss: 179451163.0545 - mae: 9849.0879 - val_loss: 899285557.5273 - val_mae: 19340.7188\n",
      "Epoch 993/1000\n",
      "880/880 [==============================] - 0s 86us/step - loss: 149378346.7636 - mae: 8948.0137 - val_loss: 976708708.0727 - val_mae: 20986.3574\n",
      "Epoch 994/1000\n",
      "880/880 [==============================] - 0s 81us/step - loss: 169617403.9273 - mae: 9560.8076 - val_loss: 978458946.3273 - val_mae: 20618.9902\n",
      "Epoch 995/1000\n",
      "880/880 [==============================] - 0s 73us/step - loss: 159554625.4545 - mae: 9358.2275 - val_loss: 940216884.3636 - val_mae: 19514.0371\n",
      "Epoch 996/1000\n",
      "880/880 [==============================] - 0s 80us/step - loss: 155597612.8000 - mae: 9315.6201 - val_loss: 977250148.0727 - val_mae: 20451.4336\n",
      "Epoch 997/1000\n",
      "880/880 [==============================] - 0s 118us/step - loss: 143678219.2000 - mae: 8815.8916 - val_loss: 981494988.8000 - val_mae: 21289.3281\n",
      "Epoch 998/1000\n",
      "880/880 [==============================] - 0s 105us/step - loss: 168507411.6364 - mae: 9632.4443 - val_loss: 937900656.8727 - val_mae: 20202.3555\n",
      "Epoch 999/1000\n",
      "880/880 [==============================] - 0s 100us/step - loss: 135938475.0545 - mae: 8547.1162 - val_loss: 941955587.4909 - val_mae: 19684.4883\n",
      "Epoch 1000/1000\n",
      "880/880 [==============================] - 0s 108us/step - loss: 137850049.4545 - mae: 8512.1436 - val_loss: 977031753.3091 - val_mae: 20821.1914\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x_train,y,batch_size=128,epochs=1000,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h=hist.history\n",
    "plt.plot(h['val_loss'],label=\"validation loss\")\n",
    "plt.plot(h['loss'],label=\"Training loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h['mae'])\n",
    "plt.plot(h['val_mae'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 1)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 62356.25 ],\n",
       "       [121264.77 ],\n",
       "       [138348.05 ],\n",
       "       [149427.84 ],\n",
       "       [114559.36 ],\n",
       "       [363079.47 ],\n",
       "       [236420.27 ],\n",
       "       [211417.95 ],\n",
       "       [175282.77 ],\n",
       "       [335596.62 ],\n",
       "       [185435.2  ],\n",
       "       [188458.16 ],\n",
       "       [110478.125],\n",
       "       [139296.42 ],\n",
       "       [117566.64 ],\n",
       "       [290717.88 ],\n",
       "       [174716.38 ],\n",
       "       [145108.22 ],\n",
       "       [148603.3  ],\n",
       "       [117786.266],\n",
       "       [103469.88 ],\n",
       "       [221068.2  ],\n",
       "       [ 98575.31 ],\n",
       "       [ 94501.93 ],\n",
       "       [155803.34 ],\n",
       "       [118480.9  ],\n",
       "       [200727.95 ],\n",
       "       [263522.84 ],\n",
       "       [221015.17 ],\n",
       "       [133803.89 ],\n",
       "       [134645.27 ],\n",
       "       [116318.445],\n",
       "       [180194.12 ],\n",
       "       [253627.23 ],\n",
       "       [184367.19 ],\n",
       "       [ 97517.74 ],\n",
       "       [117891.805],\n",
       "       [ 94374.734],\n",
       "       [232954.2  ],\n",
       "       [109207.92 ],\n",
       "       [132247.88 ],\n",
       "       [166238.2  ],\n",
       "       [396413.2  ],\n",
       "       [112132.58 ],\n",
       "       [102765.84 ],\n",
       "       [144482.7  ],\n",
       "       [157718.64 ],\n",
       "       [172876.14 ],\n",
       "       [ 91457.08 ],\n",
       "       [160256.9  ],\n",
       "       [123991.19 ],\n",
       "       [221860.53 ],\n",
       "       [206560.64 ],\n",
       "       [120287.695],\n",
       "       [210973.14 ],\n",
       "       [212503.88 ],\n",
       "       [180231.05 ],\n",
       "       [214086.7  ],\n",
       "       [258941.02 ],\n",
       "       [186035.89 ],\n",
       "       [151009.39 ],\n",
       "       [202769.39 ],\n",
       "       [140333.98 ],\n",
       "       [152921.72 ],\n",
       "       [209888.7  ],\n",
       "       [224310.02 ],\n",
       "       [224497.86 ],\n",
       "       [204232.88 ],\n",
       "       [229300.8  ],\n",
       "       [479506.4  ],\n",
       "       [134752.98 ],\n",
       "       [244084.39 ],\n",
       "       [176773.69 ],\n",
       "       [178782.55 ],\n",
       "       [227317.3  ],\n",
       "       [297798.53 ],\n",
       "       [124573.305],\n",
       "       [109786.51 ],\n",
       "       [120394.15 ],\n",
       "       [ 98199.18 ],\n",
       "       [329020.5  ],\n",
       "       [236869.2  ],\n",
       "       [303694.3  ],\n",
       "       [157580.28 ],\n",
       "       [358395.6  ],\n",
       "       [119891.3  ],\n",
       "       [151848.73 ],\n",
       "       [308818.53 ],\n",
       "       [188926.56 ],\n",
       "       [185592.02 ],\n",
       "       [296130.72 ],\n",
       "       [191232.9  ],\n",
       "       [132439.94 ],\n",
       "       [144403.19 ],\n",
       "       [152417.16 ],\n",
       "       [170539.89 ],\n",
       "       [227959.25 ],\n",
       "       [150423.02 ],\n",
       "       [164410.34 ],\n",
       "       [147623.31 ],\n",
       "       [ 95725.6  ],\n",
       "       [200239.25 ],\n",
       "       [119169.68 ],\n",
       "       [215035.55 ],\n",
       "       [160479.08 ],\n",
       "       [316118.78 ],\n",
       "       [126304.03 ],\n",
       "       [209414.1  ],\n",
       "       [136005.14 ],\n",
       "       [289905.06 ],\n",
       "       [196187.17 ],\n",
       "       [200594.89 ],\n",
       "       [ 89571.555],\n",
       "       [143335.95 ],\n",
       "       [135275.22 ],\n",
       "       [105304.13 ],\n",
       "       [147782.97 ],\n",
       "       [234245.58 ],\n",
       "       [ 69216.586],\n",
       "       [ 90766.36 ],\n",
       "       [102052.97 ],\n",
       "       [141291.34 ],\n",
       "       [172516.44 ],\n",
       "       [127988.45 ],\n",
       "       [197080.28 ],\n",
       "       [142402.86 ],\n",
       "       [237935.33 ],\n",
       "       [160296.88 ],\n",
       "       [327818.22 ],\n",
       "       [148121.75 ],\n",
       "       [ 57192.426],\n",
       "       [142845.33 ],\n",
       "       [104697.15 ],\n",
       "       [129476.81 ],\n",
       "       [158028.19 ],\n",
       "       [162770.72 ],\n",
       "       [163168.08 ],\n",
       "       [219521.81 ],\n",
       "       [139052.3  ],\n",
       "       [240066.86 ],\n",
       "       [213570.02 ],\n",
       "       [212404.31 ],\n",
       "       [168460.17 ],\n",
       "       [443585.72 ],\n",
       "       [170009.58 ],\n",
       "       [179353.73 ],\n",
       "       [200485.05 ],\n",
       "       [144254.52 ],\n",
       "       [189245.22 ],\n",
       "       [121327.45 ],\n",
       "       [255000.86 ],\n",
       "       [213214.62 ],\n",
       "       [125724.69 ],\n",
       "       [176178.05 ],\n",
       "       [198966.83 ],\n",
       "       [135990.52 ],\n",
       "       [322536.1  ],\n",
       "       [104134.77 ],\n",
       "       [176114.45 ],\n",
       "       [167343.77 ],\n",
       "       [174194.73 ],\n",
       "       [130161.55 ],\n",
       "       [161608.53 ],\n",
       "       [187605.53 ],\n",
       "       [174239.36 ],\n",
       "       [182827.45 ],\n",
       "       [155650.4  ],\n",
       "       [406852.22 ],\n",
       "       [340625.   ],\n",
       "       [136369.4  ],\n",
       "       [186342.92 ],\n",
       "       [163891.45 ],\n",
       "       [157250.19 ],\n",
       "       [176338.19 ],\n",
       "       [138210.33 ],\n",
       "       [159548.42 ],\n",
       "       [173481.27 ],\n",
       "       [231030.95 ],\n",
       "       [251138.2  ],\n",
       "       [ 81994.01 ],\n",
       "       [214603.52 ],\n",
       "       [186849.25 ],\n",
       "       [157102.83 ],\n",
       "       [156160.89 ],\n",
       "       [168466.88 ],\n",
       "       [129721.59 ],\n",
       "       [160080.33 ],\n",
       "       [277749.8  ],\n",
       "       [271065.7  ],\n",
       "       [263895.75 ],\n",
       "       [156131.36 ],\n",
       "       [122205.98 ],\n",
       "       [ 90120.83 ],\n",
       "       [184807.61 ],\n",
       "       [106193.875],\n",
       "       [134727.16 ],\n",
       "       [145532.38 ],\n",
       "       [137953.84 ],\n",
       "       [115521.45 ],\n",
       "       [169627.72 ],\n",
       "       [233001.19 ],\n",
       "       [142872.39 ],\n",
       "       [329627.22 ],\n",
       "       [222232.7  ],\n",
       "       [135084.42 ],\n",
       "       [369011.16 ],\n",
       "       [196945.83 ],\n",
       "       [142338.38 ],\n",
       "       [162527.7  ],\n",
       "       [183503.31 ],\n",
       "       [281411.66 ],\n",
       "       [193504.67 ],\n",
       "       [352197.9  ],\n",
       "       [297146.38 ],\n",
       "       [124505.44 ],\n",
       "       [195863.75 ],\n",
       "       [256919.72 ],\n",
       "       [183925.92 ],\n",
       "       [298130.6  ],\n",
       "       [123658.83 ],\n",
       "       [175496.27 ],\n",
       "       [ 70787.54 ],\n",
       "       [215247.16 ],\n",
       "       [ 89025.414],\n",
       "       [243849.61 ],\n",
       "       [ 74169.4  ],\n",
       "       [ 73276.77 ],\n",
       "       [136884.42 ],\n",
       "       [302372.38 ],\n",
       "       [182662.34 ],\n",
       "       [250834.17 ],\n",
       "       [125805.   ],\n",
       "       [121172.08 ],\n",
       "       [124292.45 ],\n",
       "       [117181.61 ],\n",
       "       [165569.55 ],\n",
       "       [135634.5  ],\n",
       "       [ 75071.61 ],\n",
       "       [221180.81 ],\n",
       "       [128289.96 ],\n",
       "       [101936.66 ],\n",
       "       [170648.27 ],\n",
       "       [225389.67 ],\n",
       "       [158989.2  ],\n",
       "       [180075.05 ],\n",
       "       [112601.16 ],\n",
       "       [254198.02 ],\n",
       "       [313839.4  ],\n",
       "       [239697.28 ],\n",
       "       [158548.33 ],\n",
       "       [230305.23 ],\n",
       "       [177596.77 ],\n",
       "       [127212.984],\n",
       "       [449152.9  ],\n",
       "       [264456.97 ],\n",
       "       [179908.7  ],\n",
       "       [113815.766],\n",
       "       [155035.55 ],\n",
       "       [161546.28 ],\n",
       "       [389912.1  ],\n",
       "       [205699.61 ],\n",
       "       [250444.39 ],\n",
       "       [152122.05 ],\n",
       "       [167064.42 ],\n",
       "       [148081.39 ],\n",
       "       [234960.5  ],\n",
       "       [205656.86 ],\n",
       "       [153623.47 ],\n",
       "       [146453.98 ],\n",
       "       [247880.42 ],\n",
       "       [129726.82 ],\n",
       "       [157790.61 ],\n",
       "       [261214.92 ],\n",
       "       [357703.9  ],\n",
       "       [278704.84 ],\n",
       "       [261845.73 ],\n",
       "       [ 95105.19 ],\n",
       "       [155439.1  ],\n",
       "       [ 94177.86 ],\n",
       "       [148544.42 ],\n",
       "       [ 81535.18 ],\n",
       "       [261652.36 ],\n",
       "       [156101.81 ],\n",
       "       [183746.33 ],\n",
       "       [107371.36 ],\n",
       "       [105893.95 ],\n",
       "       [278554.4  ],\n",
       "       [173490.86 ],\n",
       "       [351982.16 ],\n",
       "       [129525.23 ],\n",
       "       [230687.75 ],\n",
       "       [ 92330.305],\n",
       "       [124540.05 ],\n",
       "       [165131.66 ],\n",
       "       [234617.92 ],\n",
       "       [299695.6  ],\n",
       "       [234259.33 ],\n",
       "       [127501.27 ],\n",
       "       [148364.58 ],\n",
       "       [168987.42 ],\n",
       "       [113747.91 ],\n",
       "       [191435.17 ],\n",
       "       [192718.92 ],\n",
       "       [274854.66 ],\n",
       "       [119614.734],\n",
       "       [252545.08 ],\n",
       "       [126096.27 ],\n",
       "       [121928.53 ],\n",
       "       [151813.92 ],\n",
       "       [243240.23 ],\n",
       "       [224157.95 ],\n",
       "       [168548.72 ],\n",
       "       [ 97601.836],\n",
       "       [280971.53 ],\n",
       "       [185256.77 ],\n",
       "       [209286.58 ],\n",
       "       [161085.75 ],\n",
       "       [394984.62 ],\n",
       "       [147536.88 ],\n",
       "       [260006.64 ],\n",
       "       [176336.16 ],\n",
       "       [160142.33 ],\n",
       "       [144631.28 ],\n",
       "       [ 59048.863],\n",
       "       [136351.92 ],\n",
       "       [158221.58 ],\n",
       "       [269125.53 ],\n",
       "       [145107.8  ],\n",
       "       [102487.516],\n",
       "       [181620.11 ],\n",
       "       [184405.48 ],\n",
       "       [127249.1  ],\n",
       "       [ 97548.28 ],\n",
       "       [190869.22 ],\n",
       "       [165378.4  ],\n",
       "       [153348.31 ],\n",
       "       [120719.25 ],\n",
       "       [321071.   ],\n",
       "       [140021.83 ],\n",
       "       [173210.86 ],\n",
       "       [164152.2  ],\n",
       "       [143703.7  ],\n",
       "       [344412.94 ],\n",
       "       [106547.03 ],\n",
       "       [197666.9  ],\n",
       "       [ 93984.19 ],\n",
       "       [173355.72 ],\n",
       "       [271800.56 ],\n",
       "       [134686.78 ],\n",
       "       [ 86785.805],\n",
       "       [153731.31 ],\n",
       "       [228784.86 ],\n",
       "       [133848.34 ],\n",
       "       [140653.   ],\n",
       "       [185063.34 ],\n",
       "       [183285.92 ],\n",
       "       [178926.56 ],\n",
       "       [103869.33 ],\n",
       "       [151768.86 ],\n",
       "       [133295.39 ]], dtype=float32)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=y_predicted.reshape((360,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.arange(1101,1461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360,)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Id':labels,'SalePrice':y_predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1101</td>\n",
       "      <td>62356.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>121264.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1103</td>\n",
       "      <td>138348.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1104</td>\n",
       "      <td>149427.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1105</td>\n",
       "      <td>114559.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1106</td>\n",
       "      <td>363079.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1107</td>\n",
       "      <td>236420.265625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1101   62356.250000\n",
       "1  1102  121264.773438\n",
       "2  1103  138348.046875\n",
       "3  1104  149427.843750\n",
       "4  1105  114559.359375\n",
       "5  1106  363079.468750\n",
       "6  1107  236420.265625"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('y_predicted_800-300-200-100-50-20-1_neuron_sckit_learn.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
